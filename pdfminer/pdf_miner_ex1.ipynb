{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Miner\n",
    "\n",
    "* https://pypi.org/project/pdfminer/\n",
    "* https://github.com/pdfminer/pdfminer.six\n",
    "* https://pdfminersix.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../AutoGen_LLM_agent.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published as a conference paper at COLM 2024\n",
      "\n",
      "AutoGen: Enabling Next-Gen LLM Applications\n",
      "via Multi-Agent Conversations\n",
      "\n",
      "Qingyun Wu∗\n",
      "Penn State University\n",
      "qingyun@autogen.team\n",
      "\n",
      "Gagan Bansal\n",
      "Microsoft Research\n",
      "gaganbansal@microsoft.com\n",
      "\n",
      "Jieyu Zhang\n",
      "University of Washington\n",
      "jieyuz2@cs.washington.edu\n",
      "\n",
      "Yiran Wu\n",
      "Penn State University\n",
      "yiran.wu@psu.edu\n",
      "\n",
      "Beibin Li\n",
      "Microsoft Research\n",
      "beibin.li@microsoft.com\n",
      "\n",
      "Erkang Zhu\n",
      "Microsoft Research\n",
      "erkang.zhu@microsoft.com\n",
      "\n",
      "Li Jiang\n",
      "Microsoft\n",
      "lijiang1@microsoft.com\n",
      "\n",
      "Xiaoyun Zhang\n",
      "Microsoft\n",
      "xiaoyun.zhang@microsoft.com\n",
      "\n",
      "Shaokun Zhang\n",
      "Penn State University\n",
      "shaokun.zhang@psu.edu\n",
      "\n",
      "Jiale Liu\n",
      "Penn State University\n",
      "jjl7199@psu.edu\n",
      "\n",
      "Ahmed Awadallah\n",
      "Microsoft Research\n",
      "hassanam@microsoft.com\n",
      "\n",
      "Ryen W. White\n",
      "Microsoft Research\n",
      "ryenw@microsoft.com\n",
      "\n",
      "Doug Burger\n",
      "Microsoft Research\n",
      "dburger@microsoft.com\n",
      "\n",
      "Chi Wang*\n",
      "Microsoft Research\n",
      "chi@autogen.team\n",
      "\n",
      "Abstract\n",
      "\n",
      "We present AutoGen,1 an open-source framework that allows developers to\n",
      "build LLM applications by composing multiple agents to converse with each\n",
      "other to accomplish tasks. AutoGen agents are customizable, conversable,\n",
      "and can operate in various modes that employ combinations of LLMs,\n",
      "human inputs, and tools. It also enables developers to create flexible agent\n",
      "behaviors and conversation patterns for different applications using both\n",
      "natural language and code. AutoGen serves as a generic infrastructure\n",
      "and is widely used by AI practitioners and researchers to build diverse\n",
      "applications of various complexities and LLM capacities. We demonstrate\n",
      "the framework’s effectiveness with several pilot applications, on domains\n",
      "ranging from mathematics and coding to question-answering, supply-chain\n",
      "optimization, online decision-making, and entertainment.\n",
      "\n",
      "1\n",
      "\n",
      "Introduction\n",
      "\n",
      "Large language models (LLMs) are becoming a crucial building block in developing power-\n",
      "ful agents that utilize LLMs for reasoning, tool usage, and adapting to new observations (Yao\n",
      "et al., 2022; Xi et al., 2023; Wang et al., 2023). As the scope and complexity of tasks suitable\n",
      "for LLMs increase, a natural strategy for enhancing agent capabilities is to employ multiple\n",
      "cooperating agents. Prior work suggests that multiple agents can help encourage divergent\n",
      "thinking (Liang et al., 2023), improve factuality and reasoning (Du et al., 2023; Naik et al.,\n",
      "2023), and provide guardrails (Wu et al., 2023). Given the early promising evidence, an\n",
      "intriguing question is: How can we facilitate the development of LLM applications that span\n",
      "a broad spectrum of domains and complexities using a multi-agent approach? Our insight\n",
      "\n",
      "∗Equal contribution\n",
      "1https://github.com/microsoft/autogen\n",
      "\n",
      "1\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 1: AutoGen enables diverse LLM-based applications using multi-agent conversations.\n",
      "(Top-left) AutoGen agents are conversable, customizable, and can be based on LLMs, tools,\n",
      "humans, or even a combination of them. (Top-middle) Agents can converse to solve tasks.\n",
      "(Right) They can form a chat, potentially with humans in the loop.\n",
      "(Bottom-left) The\n",
      "framework supports flexible conversation patterns.\n",
      "\n",
      "is to use multi-agent conversations. There are at least three reasons confirming its general\n",
      "feasibility and utility, thanks to recent advances in LLMs: First, chat-optimized LLMs, such\n",
      "as GPT-4, demonstrate ability to incorporate feedback. LLM agents can cooperate through\n",
      "conversations with each other or humans, for example, in a dialogue where agents provide\n",
      "and seek reasoning, observations, critiques, and validation. Second, because a single LLM\n",
      "can exhibit a broad range of capabilities, conversations between differently configured\n",
      "agents can help combine these broad LLM capabilities in a modular and complementary\n",
      "manner. Third, LLMs have demonstrated the ability to solve complex tasks when broken\n",
      "into simpler sub-tasks. Multi-agent conversations can intuitively facilitate this partitioning\n",
      "and integration.\n",
      "We desire a multi-agent conversation framework with generic abstraction and effective\n",
      "implementation that has the flexibility to satisfy different application needs. Achieving this\n",
      "requires addressing two critical questions: (1) How to design individual agents that are\n",
      "capable, reusable, customizable, and effective in multi-agent collaboration? (2) How can\n",
      "we develop a straightforward, unified interface that accommodates a wide range of agent\n",
      "conversation patterns? In practice, applications of varying complexities may need distinct\n",
      "sets of agents with specific capabilities and may require different conversation patterns,\n",
      "such as single- or multi-turn dialogues, different human involvement modes, and static vs.\n",
      "dynamic conversations. Moreover, developers may prefer the flexibility to program agent\n",
      "interactions in natural language or code. We present AutoGen, a generalized multi-agent\n",
      "conversation framework (Figure 1), based on the following new concepts:\n",
      "\n",
      "1 Customizable and conversable agents. AutoGen uses a generic agent design that can\n",
      "leverage LLMs, human inputs, tools, or a combination thereof. Developers can conve-\n",
      "niently create agents with different roles or responsibilities by selecting and configuring a\n",
      "subset of built-in capabilities or defining new capabilities. To make these agents suitable\n",
      "for multi-agent conversation, every agent is made conversable – they can receive, react,\n",
      "and respond to messages. When configured properly, an agent can hold multiple turns\n",
      "of conversations with other agents autonomously or with humans in the loop. The\n",
      "conversable agent design leverages the strong capability of the most advanced LLMs\n",
      "in taking feedback and making progress via conversation, and also allows combining\n",
      "capabilities of LLMs in a modular fashion. (Section 2.1)\n",
      "\n",
      "2 Conversation programming. A fundamental insight of AutoGen is to simplify and unify\n",
      "complex LLM applications as multi-agent conversations. Thus, AutoGen adopts a pro-\n",
      "gramming paradigm centered around these inter-agent conversations. We refer to this\n",
      "paradigm as conversation programming, which streamlines the development of intricate\n",
      "applications via two primary steps: (1) defining a set of conversable agents with specific\n",
      "capabilities and roles; (2) programming the interaction behavior between agents via\n",
      "conversation-centric computation and control. Both steps can be achieved via a fusion of\n",
      "\n",
      "2\n",
      "\n",
      "Agent CustomizationFlexible Conversation PatternsMulti-Agent ConversationsExecute the following code…Got it! Here is the revised code …No, please plot % change!Plot a chart of META and TESLA stock price change YTD.Output:$MonthOutput:%MonthError package yfinanceis not installedSorry! Please first pip install yfinanceand then execute the codeInstalling…Example Agent ChatSequential ChatNested ChatGroup ChatHierarchical Chat……………………………………\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "natural and programming languages. AutoGen provides ready-to-use implementations\n",
      "and also allows easy extension and experimentation for both steps. (Section 2.2)\n",
      "\n",
      "We offer a suite of multi-agent applications realized with AutoGen, showcasing the frame-\n",
      "work’s ability to support applications of varied complexities. With these applications, we\n",
      "demonstrate AutoGen’s potential to significantly enhance task completion performance and\n",
      "innovate LLM usage while minimizing development effort. Beyond the demonstrated\n",
      "applications, AutoGen has also seen widespread adoption in the wild, fostering a vibrant\n",
      "and active community.\n",
      "Related Work. Several contemporaneous explorations of multi-agent approaches exist,\n",
      "including Generative Agents (Park et al., 2023), multi-agent debate (Liang et al., 2023; Du\n",
      "et al., 2023), CAMEL (Li et al., 2023b), BabyAGI (BabyAGI, 2023), MetaGPT (Hong et al.,\n",
      "2023), ChatDev (Qian et al., 2023), AgentVerse (Chen et al., 2023b), AutoAgents (Chen\n",
      "et al., 2023a). These systems are designed for specific types of scenarios or problem-solving\n",
      "paradigms, which limits their flexibility and generalizability as comprehensive frameworks.\n",
      "For instance, MetaGPT and ChatDev prioritize software engineering tasks and only sup-\n",
      "port certain multi-agent structures, such as chains or Standardized Operating Procedures.\n",
      "AgentVerse primarily simulates the problem-solving processes of a human group following\n",
      "a sequence of pre-defined stages. CAMEL supports multi-agent systems with two or three\n",
      "agents following a fixed workflow pattern. One notable difference of AutoGen is that it\n",
      "supports diverse workflows because of its composable conversation patterns and does not\n",
      "explicitly restrict the number of agents. We include an expanded discussion of this related\n",
      "work and single-agent systems/frameworks in Appendix B.\n",
      "\n",
      "2 The AutoGen Framework\n",
      "\n",
      "To reduce the effort required for developers to create complex LLM applications across\n",
      "various domains, a core design principle of AutoGen is to streamline them using multi-\n",
      "agent conversations. This approach also aims to maximize the reusability of implemented\n",
      "agents. This section introduces the two key concepts of AutoGen: conversable agents and\n",
      "conversation programming.\n",
      "\n",
      "2.1 Conversable Agents\n",
      "\n",
      "In AutoGen, a conversable agent is an entity with a specific role that can send message to and\n",
      "receive message from the other conversable agents, e.g., to start or continue a conversation.\n",
      "It maintains its internal context based on sent and received messages and can be configured\n",
      "to possess a set of capabilities, e.g., enabled by LLMs, tools, human input, etc. The agents\n",
      "can act according to the programmed behavior patterns described next.\n",
      "Agent capabilities powered by LLMs, humans, and tools. AutoGen allows flexibility\n",
      "to equip its agents with various capabilities, which directly affect how it processes and\n",
      "responds to messages. The built-in composable agent capabilities include: 1) LLMs. LLM-\n",
      "backed agents utilize advanced capabilities such as role-playing, implicit state inference,\n",
      "making progress based on conversation history, and coding. These capabilities can be\n",
      "combined and enhanced in different ways via novel prompting techniques2. AutoGen also\n",
      "offers enhanced LLM inference features such as result caching, error handling, message\n",
      "templating, etc., via an enhanced LLM inference layer. 2) Humans. Human involvement is\n",
      "desired or even essential in many LLM applications. AutoGen lets a human participate in\n",
      "agent conversation via human-backed agents, which could solicit human inputs at certain\n",
      "rounds of a conversation depending on the agent configuration. The default user proxy agent\n",
      "allows configurable human involvement levels and patterns, e.g., frequency and conditions\n",
      "for requesting human input including the option for humans to skip providing input. 3)\n",
      "Tools. Tool-backed agents have the capability to execute tools via code execution or function\n",
      "\n",
      "2Appendix D presents an example of such novel prompting techniques which empowers the default\n",
      "LLM-backed assistant agent in AutoGen to converse with other agents in multi-step problem-solving.\n",
      "\n",
      "3\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 2: Illustration of how to use AutoGen to program a multi-agent conversation. The\n",
      "top sub-figure illustrates the built-in conversable agents provided by AutoGen. The middle\n",
      "sub-figure shows an example of using AutoGen to develop a two-agent system with a custom\n",
      "reply function. The bottom sub-figure illustrates the resulting automated agent chat from\n",
      "the two-agent system during program execution.\n",
      "\n",
      "execution. For example, the default user proxy agent in AutoGen is able to execute code\n",
      "suggested by LLMs, or make LLM-suggested function calls.\n",
      "Agent customization. Based on application-specific needs, each agent can be configured to\n",
      "have a mix of basic back-end types to exhibit complex behavior in multi-agent conversations.\n",
      "AutoGen allows easy creation of agents with specialized capabilities and roles by reusing or\n",
      "extending the built-in agents. The yellow-shaded area of Figure 2 provides a sketch of the\n",
      "built-in agents in AutoGen. The ConversableAgent class is the most basic agent abstraction\n",
      "and, by default, can use LLMs, humans, and tools. The AssistantAgent and UserProxyAgent\n",
      "are two pre-configured ConversableAgent subclasses, each representing a common usage\n",
      "mode, i.e., acting as an AI assistant (backed by LLMs) and acting as a human proxy to\n",
      "solicit human input or execute code/function calls (backed by humans and/or tools). In the\n",
      "example on the right-hand side of Figure 1, an LLM-backed assistant agent and a tool- and\n",
      "human-backed user proxy agent are deployed together to tackle a task. Here, the assistant\n",
      "agent generates a solution with the help of LLMs and passes the solution to the user proxy\n",
      "agent. Then, the user proxy agent solicits human inputs or executes the assistant’s code\n",
      "and passes the results as feedback back to the assistant. One can compose a complex agent\n",
      "using nested chat (introduced in the next subsection) among simpler agents and increae the\n",
      "complexity recursively.\n",
      "\n",
      "4\n",
      "\n",
      "2 Initiate Conversations:A.initiate_chat(“Plot a chart of META and TESLA stock price change YTD.”, B)Assistant BUser Proxy AAutoGenAgentsDeveloper Code# This funcwill be invoked in generate_replyA.register_reply(B,  reply_func_A2B)def reply_func_A2B(msg):ouput= input_from_human()…if not ouput:if msg includes code:output = execute(msg)return outputConversableAgentAssistantAgentUserProxyAgenthuman_input_mode= “NEVER”code_execution_config= FalseDEFAULT_SYSTEM_MESSAGE = “You are a helpful AI assistant…In the following cases, suggest python code…”human_input_mode=“ALWAYS”GroupChatManagerhuman_input_mode= “NEVER”group_chat= [              ] # Note: when no reply funcis registered, a list of default reply functions will be used. Agent Customization:Program ExecutionPlot a chart of META and TESLA stock price change YTD.Execute the following code…sendreceivereceiveConversation-Centric Computationgenerate_replyError: package yfinanceis not installedsendgenerate_replySorry! Please first pip install yfinanceand then executeConversation-Driven Control Flowgenerate_replyThe Resulting Automated Agent Chat:…1.2 Register a Custom Reply Func:1.1 Define Agents:Unified Conversation Interfaces:•send•receive •generate_reply\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "2.2 Conversation Programming\n",
      "\n",
      "To develop applications where agents make meaningful progress on tasks, developers also\n",
      "need to be able to specify and properly control these multi-agent conversations. To this\n",
      "end, AutoGen utilizes conversation programming, a paradigm that concerns two concepts: the\n",
      "first is computation – the actions agents take to compute their response in a multi-agent\n",
      "conversation. And the second is control flow – the order and conditions under which\n",
      "individual computations in the conversation are executed or evaluated. As we will show in\n",
      "the applications section, the ability to program these helps implement many flexible multi-\n",
      "agent conversation patterns. In AutoGen, agent computations are conversation-centric. An\n",
      "agent takes actions based on conversations it is involved in, and these actions further lead\n",
      "to message passing for subsequent conversations. Similarly, control flow is conversation-\n",
      "driven – the participating agents’ decisions on which agents to send messages to and the\n",
      "procedure of computation are functions of the inter-agent conversation. This paradigm\n",
      "facilitates intuitive reasoning about complex workflows through actions of agents and\n",
      "message-passing between agents.\n",
      "Figure 2 provides a simple illustration. The middle sub-figure shows how each individual\n",
      "agent performs its role-specific, conversation-centric computations to generate responses\n",
      "(e.g., via LLM inference calls and code execution).The bottom sub-figure demonstrates a\n",
      "conversation-based control flow. When the assistant receives a message, the user proxy agent\n",
      "generates a reply based on code execution or solicits human inputs. The task progresses\n",
      "through conversations displayed in the dialog box. AutoGen features the following design\n",
      "patterns to facilitate conversation programming.\n",
      "Unified interfaces and auto-reply mechanisms for automated agent chat. Agents in\n",
      "AutoGen have unified conversation interfaces for performing the corresponding conversation-\n",
      "centric computation. Those low-level interfaces include:\n",
      "\n",
      "• send/receive for sending/receiving messages; and\n",
      "• generate reply for taking actions and generating a response based on the received\n",
      "\n",
      "message;\n",
      "\n",
      "• register reply for registering custom reply function.\n",
      "\n",
      "AutoGen also introduces and by default adopts an agent auto-reply mechanism to realize\n",
      "conversation-driven control: Once an agent receives a message from another agent, it\n",
      "automatically invokes generate reply and sends the reply back to the sender unless a\n",
      "termination condition is satisfied. AutoGen provides built-in reply functions based on LLM\n",
      "inference, code or function execution, or human input. One can also register custom reply\n",
      "functions (via the register reply interface) to customize the behavior pattern of an agent,\n",
      "e.g., to chat with another agent before replying to the sender agent realizing the nested chat\n",
      "conversation pattern. Under this mechanism, once the reply functions are registered, and\n",
      "the conversation is initialized, the conversation flow is naturally induced, and thus the agent\n",
      "conversation proceeds naturally without any extra control plane, i.e., a special module that\n",
      "controls the conversation flow. For example, with the developer code in the blue-shaded\n",
      "area (marked “Developer Code”) of Figure 2, one can readily trigger the conversation among\n",
      "the agents, and the conversation would proceed automatically, as shown in the dialog box in\n",
      "the grey shaded area (marked “Program Execution”) of Figure 2. The auto-reply mechanism\n",
      "provides a decentralized, modular, and unified way to define the workflow.\n",
      "Control by fusion of programming and natural language. AutoGen allows the usage of\n",
      "programming and natural language in various control flow management patterns:\n",
      "\n",
      "• Natural-language control via LLMs: One can control the conversation flow by prompting\n",
      "LLM-backed agents with natural language. For instance, the default system message of\n",
      "the built-in AssistantAgent uses natural language to instruct agents to write code and\n",
      "debug when needed. It also guides the agent to confine LLM outputs, making it easier for\n",
      "other agents to consume. More examples of such controls can be found in Appendix D.\n",
      "• Programming-language control: In AutoGen, Python code can be used to specify the\n",
      "termination condition, human input mode, and tool execution logic, e.g., the max number\n",
      "\n",
      "5\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "of auto replies. One can also register programmed auto-reply functions to control the con-\n",
      "versation flow with Python code, as shown in the code block identified as “Conversation-\n",
      "Driven Control Flow” in Figure 2.\n",
      "\n",
      "• Control transition between natural and programming language: AutoGen also supports\n",
      "flexible control transition between natural and programming language. One can achieve\n",
      "transition from code to natural-language control by invoking an LLM inference containing\n",
      "certain control logic in a customized reply function; or transition from natural language\n",
      "to code control via LLM-proposed function calls (Eleti et al., 2023).\n",
      "\n",
      "Composable conversation patterns. The conversation programming paradigm enables the\n",
      "composition of multi-agent conversations with diverse patterns, both statically and dynami-\n",
      "cally. For enhanced usability, we provide interfaces for constructing several commonly used\n",
      "conversation patterns, including two-agent chat, sequential chats, nested chat and group chat. We\n",
      "provide the detailed interfaces for specifying these patterns in Appendix D. Beyond these\n",
      "built-in patterns, one can employ these higher-level interfaces – and the low-level interfaces\n",
      "such as register reply if necessary – recursively to compose more complex and creative\n",
      "patterns, e.g., a nested chat with a group chat nested within, allowing one agent to create its\n",
      "inner monologue, realizing the Society of Mind idea from Minsky (1988). The composed\n",
      "conversation workflow can be static or dynamic. AutoGen provides a few general ways to\n",
      "achieve dynamic conversation flows: 1) custom reply functions and triggers. Nested chat\n",
      "and group chat are examples of conversation patterns using built-in custom reply functions.\n",
      "In nested chat, one agent can hold the current conversation while invoking conversations\n",
      "with other agents depending on the content of the current message and context. In group\n",
      "chat, one can define the speaker transition conditions based on the current conversation\n",
      "status. 2) LLM-driven function calls, in which a language model decides whether or not to\n",
      "call a particular function depending on the conversation status.\n",
      "\n",
      "3 Applications of AutoGen\n",
      "\n",
      "We demonstrate six applications using AutoGen (see Figure 3). These applications are selected\n",
      "based on their real-world relevance (A1, A2, A4, A5, A6), problem difficulty (A1, A2, A3,\n",
      "A4), and innovative potential (A5, A6). Together, these criteria showcase AutoGen’s role\n",
      "in advancing the LLM application landscape. All the applications and their evaluations\n",
      "presented in this section are based on code version 0.1.1 of the library, with code and\n",
      "instructions provided in the Reproducibility Statement section at the end of this paper.\n",
      "\n",
      "Figure 3: Six examples of applications built using AutoGen. These applications demonstrates\n",
      "AutoGen’s flexibility in supporting diverse applications with flexible conversation patterns.\n",
      "\n",
      "6\n",
      "\n",
      "A1. Math Problem SolvingA4. Supply-Chain OptimizationCommanderSafeguardWriterA6. Conversational ChessA2. Retrieval-augmented Q&ARetrieval-augmentedAssistantRetrieval-augmentedUser ProxyChess BoardHuman/AI Chess Player AHuman/AI Chess Player BStudentAssistantAssistantExpertAsk  expertBroadcastManagerSpeakA5. Dynamic Task Solving with Group ChatALFWorldExecutorAssistantGrounding AgentA3. Decision Making in Embodied Agents\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "(a) A1: Performance on MATH (w/ GPT-4).\n",
      "\n",
      "(b) A2: Q&A tasks (w/ GPT-3.5).\n",
      "\n",
      "(c) A3: Performance on ALFWorld.\n",
      "\n",
      "(d) A4: Performance on OptiGuide.\n",
      "\n",
      "Figure 4: Performance on four applications A1-A4. (a) shows that a simple two-agent system\n",
      "with built-in agents from AutoGen can be used out of the box to achieve the most competitive\n",
      "performance on math problem solving tasks; (b) shows that AutoGen can be used to realize\n",
      "effective retrieval augmentation and realize a novel interactive retrieval feature to boost\n",
      "performance on Q&A tasks; (c) shows that AutoGen can be used to introduce a three-agent\n",
      "system with a grounding agent to improve performance on ALFWorld; (d) shows that a\n",
      "multi-agent design is helpful in boosting performance in coding tasks that need safeguards.\n",
      "\n",
      "A1: Math Problem Solving\n",
      "\n",
      "Mathematics is a foundational discipline and the promise of leveraging LLMs to assist with\n",
      "math problem solving opens up a new plethora of applications and avenues for exploration,\n",
      "including personalized AI tutoring, AI research assistance, etc. This section demonstrates\n",
      "how AutoGen can help develop LLM applications for math problem solving, showcasing\n",
      "strong performance and flexibility in supporting various problem-solving paradigms.\n",
      "(Scenario 1) We are able to build a system for autonomous math problem solving by directly\n",
      "reusing two built-in agents from AutoGen. We evaluate our system and several alternative\n",
      "approaches, including open-source methods such as Multi-Agent Debate (Liang et al., 2023),\n",
      "LangChain ReAct (LangChain, 2023), vanilla GPT-4, and commercial products ChatGPT +\n",
      "Code Interpreter, and ChatGPT + Plugin (Wolfram Alpha), on the MATH (Hendrycks et al.,\n",
      "2021) dataset and summarize the results in Figure 4a. We perform evaluations over 120\n",
      "randomly selected level-5 problems and on the entire3 test dataset from MATH. The results\n",
      "show that the built-in agents from AutoGen already yield better performance out of the box\n",
      "compared to the alternative approaches, even including the commercial ones. (Scenario 2)\n",
      "We also showcase a human-in-the-loop problem-solving process with the help of AutoGen. To\n",
      "incorporate human feedback with AutoGen, one only needs to set human input mode=‘ALWAYS’\n",
      "in the UserProxyAgent of the system in scenario 1. We demonstrate that this system can\n",
      "\n",
      "3We did not evaluate ChatGPT on the whole dataset since it requires substantial manual effort and\n",
      "is restricted by its hourly message-number limitation. Multi-agent debate and LangChain ReAct were\n",
      "also not evaluated since they underperformed vanilla GPT-4 on the smaller test set.\n",
      "\n",
      "7\n",
      "\n",
      "2-agent chat(via AutoGen)ChatGPT+CodeChatGPT+PluginGPT-4Multi-AgentDebateLangChainReActMethods01020304050607080Success Ratio (%)52.5%48.33%45.0%30.0%26.67%23.33%69.48%55.18%120 Level-5 problemsWhole DatasetF1RecallMetrics01020304050607080Percentage (%)25.88%66.65%15.12%58.56%22.79%62.59%RAGChat (via AutoGen)RAGChat w/o interactive retrievalDPR3-agent chat(via AutoGen)2-agent chat(via AutoGen)ReActMethods020406080100Success Ratio (%)69%54%54%77%63%66%AverageBest of 3F1RecallMetrics020406080100Percentage (%)96.00%98.00%88.00%78.00%83.00%72.00%48.00%32.00%Multi-GPT4Single-GPT4Multi-GPT3.5Single-GPT3.5\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "effectively incorporate human inputs to solve challenging problems that cannot be solved\n",
      "without humans. (Scenario 3) We further demonstrate a novel scenario where multiple\n",
      "human users can participate in the conversations during the problem-solving process.\n",
      "Our experiments and case studies for these scenarios show that AutoGen enables better\n",
      "performance or new experience compared to other solutions we experimented with. Details\n",
      "of the evaluation, including case studies in three scenarios are in Appendix E.\n",
      "\n",
      "A2: Retrieval-Augmented Q&A\n",
      "\n",
      "Retrieval augmentation generation (RAG) has emerged as a practical and effective approach\n",
      "for mitigating the intrinsic limitations of LLMs by incorporating external documents. We\n",
      "employ AutoGen to build a RAG system (Lewis et al., 2020; Parvez et al., 2021) named\n",
      "Retrieval-augmented Chat. The system consists of two agents: a Retrieval-augmented\n",
      "User Proxy agent and a Retrieval-augmented Assistant agent, both of which are extended\n",
      "from built-in agents from AutoGen. The Retrieval-augmented User Proxy includes a vector\n",
      "database (Chroma, 2023) as the context retriever. A detailed workflow description of the\n",
      "Retrieval-augmented Chat (RAGChat) is provided in Appendix E. We evaluate Retrieval-\n",
      "augmented Chat in both question-answering and code-generation scenarios. (Scenario 1) We\n",
      "first perform an evaluation regarding natural question answering on the Natural Questions\n",
      "dataset (Kwiatkowski et al., 2019) and report results in Figure 4b. In this evaluation, we\n",
      "compare our system with DPR (Dense Passage Retrieval) following an existing evaluation\n",
      "practice (Adlakha et al., 2023). Leveraging the conversational design and natural-language\n",
      "control, AutoGen introduces a novel interactive retrieval feature in this application: whenever\n",
      "the retrieved context does not contain the information, instead of terminating, the LLM-\n",
      "based assistant would reply “Sorry, I cannot find any information about... UPDATE CONTEXT.”\n",
      "which will invoke more retrieval attempts. We conduct an ablation study in which we\n",
      "prompt the assistant agent to say “I don’t know” instead of “UPDATE CONTEXT.” in cases\n",
      "where relevant information is not found, and report results in Figure 4b. The results show\n",
      "that the interactive retrieval mechanism indeed plays a non-trivial role in the process. We\n",
      "give a concrete example and results using this appealing feature in Appendix E. (Scenario\n",
      "2) We further demonstrate how Retrieval-augmented Chat aids in generating code based on\n",
      "a given codebase that contains code not included in GPT-4’s training data. Evaluation and\n",
      "demonstration details for both scenarios are included in Appendix E.\n",
      "\n",
      "A3: Decision Making in Embodied Agents\n",
      "\n",
      "In this subsection, we demonstrate how AutoGen can be used to develop effective applica-\n",
      "tions that involve interactive or online decision-making. We perform the study using the\n",
      "ALFWorld (Shridhar et al., 2021), a diverse collection of synthetic language-based interactive\n",
      "decision-making tasks in household environments. With AutoGen, we implemented a two-\n",
      "agent system for ALFWorld. It consists of an LLM-backed assistant agent for suggesting\n",
      "plans to conduct a task and an executor agent for executing actions. This system integrates\n",
      "the ReAct prompting (Yao et al., 2022) and could achieve similar performance. A common\n",
      "challenge encountered in both ReAct and the AutoGen-based two-agent system is their occa-\n",
      "sional inability to follow basic commonsense knowledge about the physical world, therefore\n",
      "getting stuck with repetitive errors. Fortunately, the modular design of AutoGen allows us\n",
      "to address this issue effectively: With AutoGen, we introduce a grounding agent, which\n",
      "supplies crucial commonsense knowledge–such as “You must find and take the object before\n",
      "you can examine it. You must go to where the target object is before you can use it.”–whenever the\n",
      "system exhibits early signs of recurring errors. It significantly enhances the system’s ability\n",
      "to avoid getting entangled in error loops. We compare the task-solving performance of the\n",
      "two variants of our system with GPT-3.5-turbo and ReAct on the 134 unseen tasks from\n",
      "ALFWorld and report results in Figure 4c. The results show that introducing a grounding\n",
      "agent leads to a 15% performance gain on average. Upon examining the systems’ outputs,\n",
      "we observe that the grounding agent, by delivering commonsense knowledge at the right\n",
      "junctures, significantly mitigated the tendency of the system to persist with a flawed plan,\n",
      "thereby avoiding the creation of error loops. For an example trajectory comparing the\n",
      "systems see Appendix E, Figure 10.\n",
      "\n",
      "8\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A4: Supply-Chain Optimization\n",
      "\n",
      "In this subsection, we use AutoGen to build a multi-agent coding system based on OptiGu-\n",
      "ide (Li et al., 2023a), a system that excels at writing code to interpret optimization solutions\n",
      "and answer user questions, such as exploring the implications of changing a supply-chain\n",
      "decision or understanding why the optimizer made a particular choice. The second sub-\n",
      "figure of Figure 3 shows the AutoGen-based implementation. The workflow is as follows: the\n",
      "end user sends questions, such as “What if we prohibit shipping from supplier 1 to roastery 2?”\n",
      "to the Commander agent. The Commander coordinates with two assistant agents, including\n",
      "the Writer and the Safeguard, to answer the question. The Writer is responsible for crafting\n",
      "code and the Safeguard is responsible for checking the code safety. With AutoGen the core\n",
      "workflow code for OptiGuide was reduced from over 430 lines to 100 lines, leading to\n",
      "significant productivity improvement. We provide a detailed comparison of user experience\n",
      "with ChatGPT+Code Interpreter and AutoGen-based OptiGuide in Appendix E, where we\n",
      "show that AutoGen-based OptiGuide could save around 3x of user’s time and reduce user\n",
      "interactions by 3 - 5 times on average. We also conduct an ablation showing that multi-agent\n",
      "abstraction is necessary. Specifically, we construct a single-agent approach where a single\n",
      "agent conducts both the code-writing and safeguard processes. We tested the single- and\n",
      "multi-agent approaches on a dataset of 100 coding tasks, which is crafted to include equal\n",
      "numbers of safe and unsafe tasks. Evaluation results as reported in Figure 4d show that the\n",
      "multi-agent design boosts the F-1 score in identifying unsafe code by 8% (with GPT-4) and\n",
      "35% (with GPT-3.5-turbo), and the recall by 20% (with GPT-4) and 40% (with GPT-3.5-turbo).\n",
      "\n",
      "A5: Dynamic Task Solving with Group Chat\n",
      "\n",
      "There are many real-world scenarios that require dynamic task solving, meaning that the\n",
      "exact workflow cannot be predetermined due to the complex nature of the tasks. For\n",
      "example, tasks involving coding and web scraping. The group chat conversation pattern in\n",
      "AutoGen is a desirable pattern in such scenarios. In a group chat, the participating agents\n",
      "share the same context and converse with the others in a dynamic manner instead of\n",
      "following a pre-defined order. Dynamic group chat relies on ongoing conversations to\n",
      "guide the flow of interaction among agents. These make dynamic group chat ideal for\n",
      "situations where collaboration without strict communication order is beneficial. In AutoGen,\n",
      "the GroupChatManager class serves as the conductor of conversation among agents and\n",
      "repeats the following three steps: dynamically selecting a speaker, collecting responses\n",
      "from the selected speaker, and broadcasting the message (Figure 3-A5). For the dynamic\n",
      "speaker-selection component, we use a role-play style prompt. Through a pilot study on\n",
      "12 manually crafted complex tasks, we observed that compared to a prompt that is purely\n",
      "based on the task, utilizing a role-play prompt often leads to more effective consideration\n",
      "of both conversation context and role alignment during the problem-solving and speaker-\n",
      "selection process. Consequently, this leads to a higher success rate and fewer LLM calls. We\n",
      "include detailed results in Appendix E.\n",
      "\n",
      "A6: Conversational Chess\n",
      "\n",
      "Using AutoGen, we developed Conversational Chess, a natural language interface game\n",
      "shown in the last sub-figure of Figure 3. It features built-in agents for players, which can\n",
      "be human or LLM, and a third-party board agent to provide information and validate\n",
      "moves based on standard rules. With AutoGen, we enabled two essential features: (1)\n",
      "Natural, flexible, and engaging game dynamics, enabled by the customizable agent design\n",
      "in AutoGen. Conversational Chess supports a range of game-play patterns, including AI-AI,\n",
      "AI-human, and human-human, with seamless switching between these modes during a\n",
      "single game. An illustrative example of these entertaining game dynamics can be found in\n",
      "Figure 15, Appendix E. (2) Grounding, which is a crucial aspect to maintain game integrity.\n",
      "During gameplay, the board agent checks each proposed move for legality; if a move is\n",
      "invalid, the agent responds with an error, prompting the player agent to re-propose a legal\n",
      "move before continuing. This process ensures that only valid moves are played and helps\n",
      "maintain a consistent gaming experience. As an ablation study, we removed the board agent\n",
      "and instead only relied on a relevant prompt “you should make sure both you and the opponent\n",
      "\n",
      "9\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "are making legal moves” to ground their move. The results highlighted that without the board\n",
      "agent, illegitimate moves caused game disruptions. The modular design offered flexibility,\n",
      "allowing swift adjustments to the board agent in response to evolving game rules or varying\n",
      "chess rule variants. A comprehensive demonstration of this ablation study is in Appendix E.\n",
      "\n",
      "4 Discussion\n",
      "\n",
      "We introduced an open-source library, AutoGen, that incorporates paradigms of conversable\n",
      "agents and conversation programming. AutoGen also provides various additional supports,\n",
      "including multimodality, asynchronous operations, and enhanced LLM inference. Further-\n",
      "more, AutoGen seamlessly interoperates with numerous single-agent systems, LLM tools,\n",
      "and libraries, such as OpenAI Assistant and MemGPT (Packer et al., 2023). Although still\n",
      "in an early stage, AutoGen is already benefiting a wide range of vertical industries and\n",
      "empowering researchers to build multi-agent AI systems for various scientific studies. For\n",
      "example, AutoGen has been used to realize a multi-agent system for accessing task utility in\n",
      "LLM-powered applications (Arabzadeh et al., 2024). AutoGen has been used in studying\n",
      "behaviors of embodied agents in organized teams (Guo et al., 2024). AutoGen is used\n",
      "for producing synthetic dataset for language model fine tuning (Mitra et al., 2024), or in\n",
      "RL environments to train LLMs for agents (Zhou et al., 2024). AutoGen is also used in\n",
      "diverse science and engineering domains such as mechanics (Ni & Buehler, 2023), protein\n",
      "discovery (Ghafarollahi & Buehler, 2024a), and material design (Ghafarollahi & Buehler,\n",
      "2024b).\n",
      "AutoGen also paves the way for numerous future directions and research opportunities. For\n",
      "instance, it is worth investigating which strategies, such as agent topology and conversation\n",
      "patterns, lead to the most effective multi-agent conversations while optimizing the overall\n",
      "efficiency, among other factors. While increasing the number of agents and other degrees of\n",
      "freedom presents opportunities for tackling more complex problems, it may also introduce\n",
      "new safety challenges that require additional studies and careful consideration. We consider\n",
      "it important future work to explore those safety implications. We provide an expanded\n",
      "discussion in Appendix C, including guidelines for using AutoGen and future work. We\n",
      "welcome contributions from the broader community.\n",
      "\n",
      "Acknowledgments\n",
      "\n",
      "The work presented was made possible through discussions with and feedback from a large\n",
      "number of colleagues, including Peter Lee, Johannes Gehrke, Eric Horvitz, Steven Lucco,\n",
      "Umesh Madan, Robin Moeur, Piali Choudhury, Saleema Amershi, Adam Fourney, Victor\n",
      "Dibia, Guoqing Zheng, Corby Rosset, Ricky Loynd, Ece Kamar, Rafah Hosn, John Langford,\n",
      "Ida Momennejad, Brian Krabach, Taylor Webb, Shanka Subhra Mondal, Wei-ge Chen, Robert\n",
      "Gruen, Yinan Li, Yue Wang, Suman Nath, Tanakorn Leesatapornwongsa, Xin Wang, Shishir\n",
      "Patil, Tianjun Zhang, Saehan Jo, Ishai Menache, Kontantina Mellou, Runlong Zhou, Feiran\n",
      "Jia, Hamed Khanpour, Hamid Palangi, Srinagesh Sharma, Julio Albinati Cortez, Amin Saied,\n",
      "Yuzhe Ma, Dujian Ding, Linyong Nan, Prateek Yadav, Shannon Shen, Ankur Mallick, Mark\n",
      "Encarnaci´on, Lars Liden, Tianwei Yue, Julia Kiseleva, Anastasia Razdaibiedina, and Luciano\n",
      "Del Corro. Li Jiang would like to thank Jeff Zheng and DJ Lan for their support during this\n",
      "work. Authors would like to especially thank many colleagues from Microsoft Research\n",
      "AI Frontiers who contributed substantially to AutoGen’s growth, key new features, and\n",
      "reliability, especially Jack Gerrits, Adam Fourney, Victor Dibia, Olga Vrousgou, Rajan Chari,\n",
      "Cheng Tan, and Ricky Loynd. Last but not least, we would like to thank individuals from\n",
      "the open-source community, including but not limited to Davor Runje, Hrushikesh Dokala,\n",
      "Mark Sze, Wael Karkoub, Yulong Zhai, Joshua Kim, Olaoluwa Ademola Salami, Rajan Chari,\n",
      "Maxim Saplin, Ikko Eltociear Ashimine, Aaron Ward, Linxin Song, David Luong, Zvi Baratz,\n",
      "Yixuan Zhai, among others for contributing to and helping maintain the open-source project.\n",
      "\n",
      "10\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "References\n",
      "Vaibhav Adlakha, Parishad BehnamGhader, Xing Han Lu, Nicholas Meade, and Siva Reddy.\n",
      "Evaluating correctness and faithfulness of instruction-following models for question\n",
      "answering. arXiv preprint arXiv:2307.16877, 2023.\n",
      "\n",
      "Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny\n",
      "Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen, et al. Guidelines for\n",
      "human-ai interaction. In Proceedings of the 2019 chi conference on human factors in computing\n",
      "systems, 2019.\n",
      "\n",
      "Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan\n",
      "\n",
      "Man´e. Concrete problems in ai safety, 2016.\n",
      "\n",
      "Negar Arabzadeh, Julia Kiseleva, Qingyun Wu, Chi Wang, Ahmed Awadallah, Victor Dibia,\n",
      "Adam Fourney, and Charles Clarke. Towards better human-agent alignment: Assessing\n",
      "task utility in llm-powered applications. arXiv preprint arXiv:2402.09015, 2024.\n",
      "\n",
      "AutoGPT. Documentation — auto-gpt. https://docs.agpt.co/, 2023.\n",
      "\n",
      "BabyAGI. Github — babyagi. https://github.com/yoheinakajima/babyagi, 2023.\n",
      "\n",
      "Carrie J. Cai, Samantha Winter, David F. Steiner, Lauren Wilcox, and Michael Terry. ”hello\n",
      "ai”: Uncovering the onboarding needs of medical practitioners for human-ai collaborative\n",
      "decision-making. Proceedings of the ACM on Human-Computer Interaction, 2019.\n",
      "\n",
      "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language\n",
      "\n",
      "models as tool makers. arXiv preprint arXiv:2305.17126, 2023.\n",
      "\n",
      "Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, B¨orje F Karlsson, Jie Fu,\n",
      "and Yemin Shi. Autoagents: A framework for automatic agent generation. arXiv preprint\n",
      "arXiv:2309.17288, 2023a.\n",
      "\n",
      "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min\n",
      "Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. Agentverse: Facilitating multi-agent col-\n",
      "laboration and exploring emergent behaviors in agents. arXiv preprint arXiv:2308.10848,\n",
      "2023b.\n",
      "\n",
      "Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang,\n",
      "Ruobing Xie, Zhiyuan Liu, and Maosong Sun. Internet of agents: Weaving a web of\n",
      "heterogeneous agents for collaborative intelligence. arXiv preprint arXiv:2407.07061, 2024.\n",
      "\n",
      "Chroma. Chromadb. https://github.com/chroma-core/chroma, 2023.\n",
      "\n",
      "Victor Dibia. LIDA: A tool for automatic generation of grammar-agnostic visualizations\n",
      "and infographics using large language models. In Proceedings of the 61st Annual Meeting\n",
      "of the Association for Computational Linguistics (Volume 3: System Demonstrations), Toronto,\n",
      "Canada, July 2023. Association for Computational Linguistics.\n",
      "\n",
      "Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt.\n",
      "\n",
      "arXiv preprint arXiv:2304.07590, 2023.\n",
      "\n",
      "Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improving\n",
      "factuality and reasoning in language models through multiagent debate. arXiv preprint\n",
      "arXiv:2305.14325, 2023.\n",
      "\n",
      "Atty Eleti, Jeff Harris, and Logan Kilpatrick. Function calling and other api updates.\n",
      "\n",
      "https://openai.com/blog/function-calling-and-other-api-updates, 2023.\n",
      "\n",
      "Alireza Ghafarollahi and Markus J. Buehler. Protagents: protein discovery via large language\n",
      "model multi-agent collaborations combining physics and machine learning. Digital\n",
      "Discovery, 3:1389–1409, 2024a.\n",
      "\n",
      "Alireza Ghafarollahi and Markus J. Buehler. Atomagents: Alloy design and discovery\n",
      "\n",
      "through physics-aware multi-modal multi-agent artificial intelligence, 2024b.\n",
      "\n",
      "11\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Guidance. Guidance. https://github.com/guidance-ai/guidance, 2023.\n",
      "\n",
      "Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia V´elez, Qingyun Wu, Huazheng\n",
      "Wang, Thomas L Griffiths, and Mengdi Wang. Embodied llm agents learn to cooperate in\n",
      "organized teams. arXiv preprint arXiv:2403.12482, 2024.\n",
      "\n",
      "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\n",
      "Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the\n",
      "math dataset. arXiv preprint arXiv:2103.03874, 2021.\n",
      "\n",
      "Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven\n",
      "Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al. Metagpt: Meta programming\n",
      "for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352, 2023.\n",
      "\n",
      "Eric Horvitz. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI\n",
      "\n",
      "conference on Human Factors in Computing Systems, 1999.\n",
      "\n",
      "HuggingFace.\n",
      "\n",
      "Transformers agent.\n",
      "\n",
      "transformers agents, 2023.\n",
      "\n",
      "https://huggingface.co/docs/transformers/\n",
      "\n",
      "Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer\n",
      "\n",
      "tasks. arXiv preprint arXiv:2303.17491, 2023.\n",
      "\n",
      "Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, Po-Yu Huang,\n",
      "Graham Neubig, Shuyan Zhou, Ruslan Salakhutdinov, and Daniel Fried. Visualwe-\n",
      "barena: Evaluating multimodal agents on realistic visual web tasks. arXiv preprint\n",
      "arXiv:2401.13649, 2024.\n",
      "\n",
      "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh,\n",
      "Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural\n",
      "questions: a benchmark for question answering research. Transactions of the Association for\n",
      "Computational Linguistics, 2019.\n",
      "\n",
      "LangChain. Introduction — langchain. https://python.langchain.com/en/latest/index.\n",
      "\n",
      "html, 2023.\n",
      "\n",
      "Mike Lewis, Denis Yarats, Yann N Dauphin, Devi Parikh, and Dhruv Batra. Deal or no deal?\n",
      "\n",
      "end-to-end learning for negotiation dialogues. arXiv preprint arXiv:1706.05125, 2017.\n",
      "\n",
      "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\n",
      "Goyal, Heinrich K ¨uttler, Mike Lewis, Wen-tau Yih, Tim Rockt¨aschel, et al. Retrieval-\n",
      "augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information\n",
      "Processing Systems, 2020.\n",
      "\n",
      "Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, and Ishai Menache. Large\n",
      "language models for supply chain optimization. arXiv preprint arXiv:2307.03875, 2023a.\n",
      "\n",
      "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard\n",
      "Ghanem. Camel: Communicative agents for ”mind” exploration of large scale language\n",
      "model society, 2023b.\n",
      "\n",
      "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang,\n",
      "Zhaopeng Tu, and Shuming Shi. Encouraging divergent thinking in large language\n",
      "models through multi-agent debate, 2023.\n",
      "\n",
      "Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang. Rein-\n",
      "forcement learning on web interfaces using workflow-guided exploration. arXiv preprint\n",
      "arXiv:1802.08802, 2018.\n",
      "\n",
      "Jerry Liu. LlamaIndex, November 2022. URL https://github.com/jerryjliu/llama index.\n",
      "\n",
      "Marvin L. Minsky. The Society of Mind. Simon & Schuster, New York, 1988. ISBN 978-0-671-\n",
      "\n",
      "65713-0.\n",
      "\n",
      "12\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Arindam Mitra, Hamed Khanpour, Corby Rosset, and Ahmed Awadallah. Orca-math:\n",
      "Unlocking the potential of slms in grade school math. arXiv preprint arXiv:2402.14830,\n",
      "2024.\n",
      "\n",
      "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou,\n",
      "Daan Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning.\n",
      "arXiv preprint arXiv:1312.5602, 2013.\n",
      "\n",
      "Ranjita Naik, Varun Chandrasekaran, Mert Yuksekgonul, Hamid Palangi, and Besmira\n",
      "Nushi. Diversity of thought improves reasoning abilities of large language models. arXiv\n",
      "preprint arXiv:2310.07088, 2023.\n",
      "\n",
      "Roberto Navigli, Simone Conia, and Bj¨orn Ross. Biases in large language models: Origins,\n",
      "\n",
      "inventory and discussion. ACM Journal of Data and Information Quality, 2023.\n",
      "\n",
      "Bo Ni and Markus J. Buehler. Mechagents: Large language model multi-agent collaborations\n",
      "\n",
      "can solve mechanics problems, generate new data, and integrate knowledge, 2023.\n",
      "\n",
      "OpenAI. ChatGPT plugins. https://openai.com/blog/chatgpt-plugins, 2023.\n",
      "\n",
      "Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah Wooders, and Joseph E\n",
      "Gonzalez. Memgpt: Towards llms as operating systems. arXiv preprint arXiv:2310.08560,\n",
      "2023.\n",
      "\n",
      "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\n",
      "Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv\n",
      "preprint arXiv:2304.03442, 2023.\n",
      "\n",
      "Md Rizwan Parvez, Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-\n",
      "Wei Chang. Retrieval augmented code generation and summarization. arXiv preprint\n",
      "arXiv:2108.11601, 2021.\n",
      "\n",
      "Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. Gorilla: Large language\n",
      "\n",
      "model connected with massive apis. arXiv preprint arXiv:2305.15334, 2023.\n",
      "\n",
      "Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and Antonio\n",
      "Torralba. Virtualhome: Simulating household activities via programs. In Proceedings of the\n",
      "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.\n",
      "\n",
      "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu,\n",
      "and Maosong Sun. Communicative agents for software development. arXiv preprint\n",
      "arXiv:2307.07924, 2023.\n",
      "\n",
      "Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng\n",
      "Yang, Zhiyuan Liu, and Maosong Sun. Scaling large-language-model-based multi-agent\n",
      "collaboration. arXiv preprint arXiv:2406.07155, 2024.\n",
      "\n",
      "SemanticKernel.\n",
      "\n",
      "Introduction — semantic kernel.\n",
      "\n",
      "semantic-kernel, 2023.\n",
      "\n",
      "https://github.com/microsoft/\n",
      "\n",
      "Bokui Shen, Fei Xia, Chengshu Li, Roberto Mart´ın-Mart´ın, Linxi Fan, Guanzhi Wang,\n",
      "Claudia P´erez-D’Arpino, Shyamal Buch, Sanjana Srivastava, Lyne Tchapmi, et al. igibson\n",
      "In 2021\n",
      "1.0: A simulation environment for interactive tasks in large realistic scenes.\n",
      "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2021.\n",
      "\n",
      "Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Hernandez, and Percy Liang. World\n",
      "of bits: An open-domain platform for web-based agents. In International Conference on\n",
      "Machine Learning. PMLR, 2017.\n",
      "\n",
      "Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and\n",
      "Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning.(2023). arXiv\n",
      "preprint cs.AI/2303.11366, 2023.\n",
      "\n",
      "13\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Cˆot´e, Yonatan Bisk, Adam Trischler, and\n",
      "Matthew Hausknecht. ALFWorld: Aligning Text and Embodied Environments for Inter-\n",
      "active Learning. In Proceedings of the International Conference on Learning Representations\n",
      "(ICLR), 2021. URL https://arxiv.org/abs/2010.03768.\n",
      "\n",
      "Linxin Song, Jiale Liu, Jieyu Zhang, Shaokun Zhang, Ao Luo, Shijian Wang, Qingyun Wu,\n",
      "and Chi Wang. Adaptive in-conversation team building for language model agents. arXiv\n",
      "preprint arXiv:2405.19425, 2024.\n",
      "\n",
      "Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets,\n",
      "Michelle Yeo, Alireza Makhzani, Heinrich K ¨uttler, John Agapiou, Julian Schrittwieser, et al.\n",
      "Starcraft ii: A new challenge for reinforcement learning. arXiv preprint arXiv:1708.04782,\n",
      "2017.\n",
      "\n",
      "Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu. Flaml: A fast and lightweight\n",
      "\n",
      "automl library. Proceedings of Machine Learning and Systems, 2021.\n",
      "\n",
      "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan\n",
      "Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based\n",
      "autonomous agents. arXiv preprint arXiv:2308.11432, 2023.\n",
      "\n",
      "Daniel S. Weld and Oren Etzioni. The first law of robotics (a call to arms). In AAAI Conference\n",
      "\n",
      "on Artificial Intelligence, 1994.\n",
      "\n",
      "Max Woolf. Langchain problem. https://minimaxir.com/2023/07/langchain-problem/,\n",
      "\n",
      "2023.\n",
      "\n",
      "Yiran Wu, Feiran Jia, Shaokun Zhang, Qingyun Wu, Hangyu Li, Erkang Zhu, Yue Wang,\n",
      "Yin Tat Lee, Richard Peng, and Chi Wang. An empirical study on challenging math\n",
      "problem solving with gpt-4. arXiv preprint arXiv:2306.01337, 2023.\n",
      "\n",
      "Yiran Wu, Tianwei Yue, Shaokun Zhang, Chi Wang, and Qingyun Wu. Stateflow: Enhancing\n",
      "llm task-solving through state-driven workflows. arXiv preprint arXiv:2403.11322, 2024.\n",
      "\n",
      "Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang,\n",
      "Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model\n",
      "based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.\n",
      "\n",
      "Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua,\n",
      "Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu, Hongjin Su, Dongchan Shin,\n",
      "Caiming Xiong, and Tao Yu. Openagents: An open platform for language agents in the\n",
      "wild. arXiv preprint arXiv:2310.10634, 2023.\n",
      "\n",
      "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and\n",
      "Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint\n",
      "arXiv:2210.03629, 2022.\n",
      "\n",
      "Shaokun Zhang, Feiran Jia, Chi Wang, and Qingyun Wu. Targeted hyperparameter optimiza-\n",
      "tion with lexicographic preferences over multiple objectives. In The Eleventh international\n",
      "conference on learning representations, 2023.\n",
      "\n",
      "Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, and\n",
      "Qingyun Wu. Offline training of language model agents with functions as learnable\n",
      "weights. In Forty-first International Conference on Machine Learning, 2024.\n",
      "\n",
      "Runlong Zhou, Simon S Du, and Beibin Li. Reflect-rl: Two-player online rl fine-tuning for\n",
      "\n",
      "lms. 2024.\n",
      "\n",
      "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\n",
      "Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for\n",
      "building autonomous agents. arXiv preprint arXiv:2307.13854, 2023.\n",
      "\n",
      "14\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Ethics statement\n",
      "\n",
      "There are several potential ethical considerations that could arise from the development and\n",
      "use of the AutoGen framework.\n",
      "• Privacy and Data Protection: The framework allows for human participation in conver-\n",
      "sations between agents. It is important to ensure that user data and conversations are\n",
      "protected, and that developers use appropriate measures to safeguard privacy.\n",
      "\n",
      "• Bias and Fairness: LLMs have been shown to exhibit biases present in their training\n",
      "data (Navigli et al., 2023). When using LLMs in the AutoGen framework, it is crucial\n",
      "to address and mitigate any biases that may arise in the conversations between agents.\n",
      "Developers should be aware of potential biases and take steps to ensure fairness and\n",
      "inclusivity.\n",
      "\n",
      "• Accountability and Transparency: As discussed in the future work section, as the frame-\n",
      "work involves multiple agents conversing and cooperating, it is important to establish\n",
      "clear accountability and transparency mechanisms. Users should be able to understand\n",
      "and trace the decision-making process of the agents involved in order to ensure account-\n",
      "ability and address any potential issues or biases.\n",
      "\n",
      "• Trust and Reliance: AutoGen leverages human understanding and intelligence while\n",
      "providing automation through conversations between agents. It is important to consider\n",
      "the impact of this interaction on user experience, trust, and reliance on AI systems. Clear\n",
      "communication and user education about the capabilities and limitations of the system\n",
      "will be essential (Cai et al., 2019).\n",
      "\n",
      "• Unintended Consequences: As discussed before, the use of multi-agent conversations and\n",
      "automation in complex tasks may have unintended consequences. Especially, allowing\n",
      "LLM agents to make changes in external environments through code execution or function\n",
      "calls, such as install packages, could be risky. Developers should carefully consider the\n",
      "potential risks and ensure that appropriate safeguards are in place to prevent harm or\n",
      "negative outcomes.\n",
      "\n",
      "Reproducibility Statement\n",
      "\n",
      "Following the best practices in the community, we aim to ensure the reproducibility of\n",
      "the results presented in this paper. The appendices and the accompanying repository are\n",
      "designed to provide readers and reviewers with comprehensive resources to understand,\n",
      "replicate, and extend our work.\n",
      "\n",
      "• Detailed descriptions of each application, including their construction and evaluations,\n",
      "\n",
      "are provided in Appendix E.\n",
      "\n",
      "are illustrated in Appendix F.\n",
      "\n",
      "• Example outputs from AutoGen and alternative approaches across different applications\n",
      "\n",
      "• A repository containing the source code of AutoGen (v0.1.1) and application evaluation\n",
      "code is provided, along with instructions for reproducing the experiments reported in\n",
      "this paper: https://github.com/qingyun-wu/autogen/tree/2024-03.\n",
      "\n",
      "15\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A Interfaces and Example Code\n",
      "\n",
      "Agent Specification. AutoGen provides a set of built-in and pre-configured conversable\n",
      "agents, which can be directly imported and used. One can further create an agent with\n",
      "customized capabilities and proper configuration when instantiating the agent.\n",
      "\n",
      "1 from autogen import ConversableAgent , AssistantAgent , UserProxyAgent\n",
      "2 user_proxy = UserProxyAgent ( name =\" user proxy \")\n",
      "\n",
      "Listing 1: Importing and using pre-configured agent classes from AutoGen\n",
      "\n",
      "1 my_assistant = ConversableAgent (\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6 )\n",
      "\n",
      "name =\" my assistant \" ,\n",
      "llm_config = my_config ,\n",
      "code_execution_config = True ,\n",
      "function_map = my_func ,\n",
      "\n",
      "Listing 2: Specifying an agent with customized capabilities\n",
      "\n",
      "High-level agent interfaces for composing diverse conversation patterns. AutoGen pro-\n",
      "vides several commonly used conversation patterns via the following interfaces:\n",
      "\n",
      "• initiate chat: two-agent chat, which is a chat involving two agents. An example is\n",
      "\n",
      "shown in Listing 4.\n",
      "\n",
      "• initiate chats: sequential chat, which involves a sequence of chats between two agents.\n",
      "This approach is particularly beneficial for tasks requiring a sequence of interdepen-\n",
      "dent multi-agent conversations. The utility of this method is exemplified in Listing 5,\n",
      "showcasing the execution of complex tasks through coordinated chat sequences.\n",
      "\n",
      "• register nested chat: nested chat, which is a chat created by a receiver agent after\n",
      "receiving a message from a sender agent and finished before the receiver agent replies to\n",
      "this message. Nested chats allow one agent to use other agents as their inner monologue\n",
      "to accomplish tasks. This abstraction is powerful as it allows one to compose agents in rich\n",
      "ways. Listing 3 gives an example in which we use this interface to nest a reflection agent\n",
      "within the user proxy agent. This could be used to realize the self-reflection idea (Shinn\n",
      "et al., 2023) to improve LLM’s reasoning and problem-solving capability.\n",
      "\n",
      "• GroupChat: group chat, which is a pattern in which participating agents have shared\n",
      "\n",
      "context. It is desirable for dynamic task solving, as detailed in A5.\n",
      "\n",
      "1 user_proxy . register_nested_chat ([{ \" recipient \": critique_agent }])\n",
      "\n",
      "Listing 3: Nested chat registration (assuming all the agent involved have been created)\n",
      "\n",
      "1 user_proxy . initiate_chat (\n",
      "2\n",
      "\n",
      "my_assistant , message =\" Plot a chart of META and TESLA stock price\n",
      "change YTD .\"\n",
      "\n",
      "3 )\n",
      "\n",
      "Listing 4: Two-agent chat (with a nested chat if the corresponding registration is done)\n",
      "\n",
      "1 initiate_chats (\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12 )\n",
      "\n",
      "},\n",
      "{\n",
      "\n",
      "[{\n",
      "\n",
      "}]\n",
      "\n",
      "\" sender \": user_proxy ,\n",
      "\" recipient \": my_assistant_1 ,\n",
      "\" message \": \" Get META and TESLA stock price change YTD .\" ,\n",
      "\n",
      "\" sender \": user_proxy ,\n",
      "\" recipient \": my_assistant_2 ,\n",
      "\" message \": \" Plot a chart based on the stock price data .\" ,\n",
      "\n",
      "Listing 5: Sequential chat\n",
      "\n",
      "16\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "B Expanded Related Work\n",
      "\n",
      "Here we examine existing LLM-based agent systems or frameworks that can be used to\n",
      "build LLM applications in detail. We categorize the related work into single-agent and multi-\n",
      "agent systems and specifically provide a summary of differentiators comparing AutoGen\n",
      "with existing multi-agent systems below. Note that many of these systems are evolving\n",
      "open-source projects, so the remarks and statements about them may only be accurate as of\n",
      "the time of writing. We refer interested readers to detailed LLM-based agent surveys (Xi\n",
      "et al., 2023; Wang et al., 2023)\n",
      "\n",
      "Single-Agent Systems:\n",
      "\n",
      "• AutoGPT: AutoGPT is an open-source implementation of an AI agent that attempts to\n",
      "autonomously achieve a given goal (AutoGPT, 2023). It follows a single-agent paradigm\n",
      "in which it augments the AI model with many useful tools, and does not support multi-\n",
      "agent collaboration.\n",
      "\n",
      "• ChatGPT+ (with code interpreter or plugin): ChatGPT, a conversational AI service\n",
      "or agent, can now be used alongside a code interpreter or plugin (currently available\n",
      "only under the premium subscription plan ChatGPT Plus) (OpenAI, 2023). The code\n",
      "interpreter enables ChatGPT to execute code, while the plugin enhances ChatGPT with a\n",
      "wide range of curated tools.\n",
      "\n",
      "• LangChain Agents: LangChain is a general framework for developing LLM-based\n",
      "applications (LangChain, 2023). LangChain Agents is a subpackage for using an LLM\n",
      "to choose a sequence of actions. There are various types of agents in LangChain Agents,\n",
      "with the ReAct agent being a notable example that combines reasoning and acting when\n",
      "using LLMs (mainly designed for LLMs prior to ChatGPT) (Yao et al., 2022). All agents\n",
      "provided in LangChain Agents follow a single-agent paradigm and are not inherently\n",
      "designed for communicative and collaborative modes. A significant summary of its\n",
      "limitations can be found in (Woolf, 2023). Due to these limitations, even the multi-agent\n",
      "systems in LangChain (e.g., re-implementation of CAMEL) are not based on LangChain\n",
      "Agents but are implemented from scratch. Their connection to LangChain lies in the use\n",
      "of basic orchestration modules provided by LangChain, such as AI models wrapped by\n",
      "LangChain and the corresponding interface.\n",
      "\n",
      "• Transformers Agent: Transformers Agent (HuggingFace, 2023) is an experimental natural-\n",
      "language API built on the transformers repository. It includes a set of curated tools and\n",
      "an agent to interpret natural language and use these tools. Similar to AutoGPT, it follows\n",
      "a single-agent paradigm and does not support agent collaboration.\n",
      "\n",
      "AutoGen differs from the single-agent systems by supporting multi-agent conversations.\n",
      "\n",
      "Multi-Agent Systems:\n",
      "\n",
      "• Multi-Agent Debate: Two recent works investigate and show that multi-agent debate\n",
      "is an effective way to encourage divergent thinking in LLMs (Liang et al., 2023) and to\n",
      "improve the factuality and reasoning of LLMs (Du et al., 2023). In both works, multiple\n",
      "LLM inference instances are constructed as multiple agents to solve problems with agent\n",
      "debate. Each agent is simply an LLM inference instance, while no tool or human is\n",
      "involved, and the inter-agent conversation needs to follow a pre-defined order. These\n",
      "works attempt to build LLM applications with multi-agent conversation, while AutoGen,\n",
      "designed as a generic infrastructure, can be used to facilitate this development and enable\n",
      "more applications with dynamic conversation patterns.\n",
      "\n",
      "• MetaGPT (Hong et al., 2023) and ChatDev (Qian et al., 2023): Both MetaGPT and\n",
      "ChatDev are multi-agent frameworks for software development. Compared to MetaGPT\n",
      "and ChatDev, AutoGen supports more flexible and complex workflows in addition to\n",
      "Standardized Operating Procedures (SOP) or chains, e.g., nested chat and group chat,\n",
      "and covers a wider range of usage scenarios beyond software engineering.\n",
      "\n",
      "• Simulacra (Park et al., 2023): This system features twenty-five generative agents in an\n",
      "interactive sandbox environment. It represents one of the initial attempts at multi-agent\n",
      "\n",
      "17\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "interaction, with a special focus on investigating whether generative agents could enable\n",
      "believable simulations of human behavior.\n",
      "\n",
      "• BabyAGI: BabyAGI (BabyAGI, 2023) is an example implementation of an AI-powered\n",
      "task management system in a Python script. In this implemented system, multiple LLM-\n",
      "based agents are used. For example, there is an agent for creating new tasks based on\n",
      "the objective and the result of the previous task, an agent for prioritizing the task list,\n",
      "and an agent for completing tasks/sub-tasks. As a multi-agent system, BabyAGI adopts\n",
      "a static agent conversation pattern, i.e., a predefined order of agent communication,\n",
      "while AutoGen supports both static and dynamic conversation patterns and additionally\n",
      "supports tool usage and human involvement.\n",
      "\n",
      "• CAMEL: CAMEL (Li et al., 2023b) is a role-playing-based agent framework supporting\n",
      "two or three agents (depending on if a critic agent is included). It demonstrates how role-\n",
      "playing can be used to let chat agents communicate with each other for task completion.\n",
      "It also records agent conversations for behavior analysis and capability understanding.\n",
      "An Inception-prompting technique is used to achieve autonomous cooperation between\n",
      "agents.\n",
      "\n",
      "Several other LLM-based multi-agent systems/frameworks have emerged following the\n",
      "initial release of our work, including AgentVerse (Chen et al., 2023b), AutoAgents (Chen\n",
      "et al., 2023a), OpenAgents (Xie et al., 2023) and IoA (Chen et al., 2024). We omit a detailed\n",
      "discussion here due to the contemporaneous nature of these developments.\n",
      "\n",
      "C Expanded Discussion\n",
      "\n",
      "The applications in Section 3 show how AutoGen not only enables new applications but\n",
      "also helps renovate existing ones. For example, in A1 (scenario 3), A5, and A6, AutoGen\n",
      "enabled the creation of multi-agent conversations that follow a dynamic pattern instead of\n",
      "a fixed back-and-forth. And in both A5 and A6, humans can participate in the activities\n",
      "together with multiple other AI agents in a conversational manner. Similarly, A1-A4 show\n",
      "how popular applications can be renovated quickly with AutoGen. Despite the complexity of\n",
      "these applications (most of them involve more than two agents or dynamic multi-turn agent\n",
      "cooperation), our AutoGen-based implementation remains simple, demonstrating promising\n",
      "opportunities to build creative applications and a large space for innovation. In reflecting\n",
      "on why these benefits can be achieved in these applications with AutoGen, we believe there\n",
      "are a few reasons:\n",
      "\n",
      "• Ease of use: The built-in agents can be used out-of-the-box, delivering strong performance\n",
      "\n",
      "even without any customization. (A1, A3)\n",
      "\n",
      "• Modularity: The division of tasks into separate agents promotes modularity in the system.\n",
      "Each agent can be developed, tested, and maintained independently, simplifying the\n",
      "overall development process and facilitating code management. (A3, A4, A5, and A6)\n",
      "\n",
      "• Programmability: AutoGen allows users to extend/customize existing agents to develop\n",
      "systems satisfying their specific needs with ease. (A1-A6). As demonstrated in A4, the\n",
      "use of AutoGen significantly streamlines the core workflow code, reducing it from over\n",
      "430 lines to just 100 lines, resulting in a fourfold reduction in code size.\n",
      "\n",
      "• Allowing human involvement: AutoGen provides a native mechanism to achieve hu-\n",
      "man participation and/or human oversight. With AutoGen, humans can seamlessly and\n",
      "optionally cooperate with AIs to solve problems or generally participate in the activity.\n",
      "AutoGen also facilitates interactive user instructions to ensure the process stays on the\n",
      "desired path. (A1, A2, A5, and A6)\n",
      "\n",
      "• Collaborative/adversarial agent interactions: Like many collaborative agent sys-\n",
      "tems (Dong et al., 2023), agents in AutoGen can share information and knowledge, to\n",
      "complement each other’s abilities and collectively arrive at better solutions. (A1, A2,\n",
      "A3, and A4). Analogously, in certain scenarios, some agents are required to work in\n",
      "an adversarial way. Relevant information is shared among different conversations in a\n",
      "controlled manner, preventing distraction or hallucination. (A4, A6). AutoGen supports\n",
      "both patterns, enabling effective utilization and augmentation of LLMs.\n",
      "\n",
      "18\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "C.1 General Guidelines for Using AutoGen\n",
      "\n",
      "Below we give some recommendations for using agents in AutoGen to accomplish a task.\n",
      "\n",
      "1. Consider using built-in agents first. For example, AssistantAgent is pre-configured\n",
      "with a carefully designed system message for generic problem-solving via code. The\n",
      "UserProxyAgent is configured to solicit human inputs and perform tool execution. Many\n",
      "problems can be solved by simply combining these two agents. When customizing\n",
      "agents for an application, consider the following options: (1) human input mode, termi-\n",
      "nation condition, code execution configuration, and LLM configuration can be specified\n",
      "when constructing an agent; (2) AutoGen supports adding instructions in an initial user\n",
      "message, which is an effective way to boost performance without needing to modify\n",
      "the system message; (3) UserProxyAgent can be extended to handle different execution\n",
      "environments and exceptions, etc.; (4) when system message modification is needed,\n",
      "consider leveraging the LLM’s capability to program its conversation flow with natural\n",
      "language.\n",
      "\n",
      "2. Start with a simple conversation topology. Consider using the two-agent chat or the\n",
      "group chat setup first, as they can often be extended with the least code. Note that\n",
      "the two-agent chat can be easily extended to involve more than two agents by using\n",
      "LLM-consumable functions in a dynamic way.\n",
      "\n",
      "3. Try to reuse built-in reply methods based on LLM, tool, or human before implementing a\n",
      "custom reply method because they can often be reused to achieve the goal in a simple way\n",
      "(e.g., the built-in agent GroupChatManager’s reply method reuses the built-in LLM-based\n",
      "reply function when selecting the next speaker, ref. A5 in Section 3).\n",
      "\n",
      "4. When developing a new application with UserProxyAgent, start with humans always in\n",
      "the loop, i.e., human input mode=‘ALWAYS’, even if the target operation mode is more\n",
      "autonomous. This helps evaluate the effectiveness of AssistantAgent, tuning the prompt,\n",
      "discovering corner cases, and debugging. Once confident with small-scale success,\n",
      "consider setting human input mode = ‘NEVER’. This enables LLM as a backend, and\n",
      "one can either use the LLM or manually generate diverse system messages to simulate\n",
      "different use cases.\n",
      "\n",
      "5. Despite the numerous advantages of AutoGen agents, there could be cases/scenarios\n",
      "where other libraries/packages could help. For example: (1) For (sub)tasks that do not\n",
      "have requirements for back-and-forth trouble-shooting, multi-agent interaction, etc., a\n",
      "unidirectional (no back-and-forth message exchange) pipeline can also be orchestrated\n",
      "with LangChain (LangChain, 2023), LlamaIndex (Liu, 2022), Guidance (Guidance, 2023),\n",
      "Semantic Kernel (SemanticKernel, 2023), Gorilla (Patil et al., 2023) or low-level inference\n",
      "API (‘autogen.oai’ provides an enhanced LLM inference layer at this level) (Dibia, 2023).\n",
      "(2) When existing tools from LangChain etc. are helpful, one can use them as tool\n",
      "backends for AutoGen agents. For example, one can readily use tools, e.g., Wolfram\n",
      "Alpha, from LangChain in AutoGen agent. (3) For specific applications, one may want\n",
      "to leverage agents implemented in other libraries/packages. To achieve this, one could\n",
      "wrap those agents as conversable agents in AutoGen and then use them to build LLM\n",
      "applications through multi-agent conversation. (4) It can be hard to find an optimal\n",
      "operating point among many tunable choices, such as the LLM inference configuration.\n",
      "Blackbox optimization packages like ‘flaml.tune’ (Wang et al., 2021; Zhang et al., 2023)\n",
      "can be used together with AutoGen to automate such tuning.\n",
      "\n",
      "C.2 Future Work\n",
      "\n",
      "This work raises many research questions and future directions.\n",
      "Designing optimal multi-agent workflows: Creating a multi-agent workflow for a given\n",
      "task can involve many decisions, e.g., how many agents to include (Qian et al., 2024),\n",
      "how to assign agent roles and agent capabilities (Song et al., 2024), how the agents should\n",
      "interact with each other (Wu et al., 2024), and whether to automate a particular part of\n",
      "the workflow. There may not exist a one-size-fits-all answer, and the best solution might\n",
      "depend on the specific application. This raises important questions: For what types of tasks\n",
      "\n",
      "19\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "and applications are multi-agent workflows most useful? How do multiple agents help in\n",
      "different applications? For a given task, what is the optimal (e.g., cost-effective) multi-agent\n",
      "workflow?\n",
      "Creating highly capable agents: AutoGen can enable the development of highly capable\n",
      "agents that leverage the strengths of LLMs, tools, and humans. Creating such agents is\n",
      "crucial to ensuring that a multi-agent workflow can effectively troubleshoot and make\n",
      "progress on a task. We believe that more systematic work will be required to develop\n",
      "guidelines for application-specific agents, to create a large OSS knowledge base of agents,\n",
      "and to create agents that can discover and upgrade their skills (Cai et al., 2023; Zhang et al.,\n",
      "2024; Song et al., 2024).\n",
      "Enabling scale, safety, and human agency: Section 3 shows how complex multi-agent\n",
      "workflows can enable new applications, and future work will be needed to assess whether\n",
      "scaling further can help solve extremely complex tasks. However, as these workflows scale\n",
      "and grow more complex, it may become difficult to log and adjust them. Thus, it will\n",
      "become essential to develop clear mechanisms and tools to track and debug their behavior.\n",
      "Otherwise, these techniques risk resulting in incomprehensible, unintelligible chatter among\n",
      "agents (Lewis et al., 2017).\n",
      "Our work also shows how complex, fully autonomous workflows with AutoGen can be\n",
      "useful, but fully autonomous agent conversations will need to be used with care. While the\n",
      "autonomous mode AutoGen supports could be desirable in many scenarios, a high level of\n",
      "autonomy can also pose potential risks, especially in high-risk applications (Amodei et al.,\n",
      "2016; Weld & Etzioni, 1994). As a result, building fail-safes against cascading failures and ex-\n",
      "ploitation, mitigating reward hacking, out of control and undesired behaviors, maintaining\n",
      "effective human oversight of applications built with AutoGen agents will become important.\n",
      "While AutoGen provides convenient and seamless involvement of humans through a user\n",
      "proxy agent, developers and stakeholders still need to understand and determine the ap-\n",
      "propriate level and pattern of human involvement to ensure the safe and ethical use of the\n",
      "technology (Horvitz, 1999; Amershi et al., 2019).\n",
      "\n",
      "D Default System Message for Assistant Agent\n",
      "\n",
      "Figure 5 shows the default system message for the built-in assistant agent in AutoGen (v0.1.1),\n",
      "where we introduce several new prompting techniques and highlight them accordingly.\n",
      "When combining these new prompting techniques together, we can program a fairly complex\n",
      "conversation even with the simplest two-agent conversation topology. This approach tries\n",
      "to exploit the capability of LLMs in implicit state inference to a large degree. LLMs do not\n",
      "follow all the instructions perfectly, so the system design requires additional mechanisms\n",
      "to manage exceptions and faults. Certain instructions can contain ambiguities, and the\n",
      "designer should either mitigate these ambiguities to enhance precision or intentionally\n",
      "retain them to allow for flexibility and address the varying situations through other means.\n",
      "\n",
      "E Application Details\n",
      "\n",
      "A1: Math Problem Solving\n",
      "\n",
      "Scenario 1: Autonomous Problem Solving. We perform both qualitative and quantitative\n",
      "evaluations in this scenario. For all evaluations, we use GPT-4 as the base model, and\n",
      "pre-install the “sympy” package in the execution environment. We compare AutoGen with\n",
      "the following LLM-based agent systems:\n",
      "\n",
      "• AutoGPT: The out-of-box AutoGPT is used. We initialize AutoGPT by setting the purpose\n",
      "to “solve math problems”, resulting in a “MathSolverGPT” with auto-generated goals.\n",
      "• ChatGPT+Plugin: We enable the Wolfram Alpha plugin (a math computation engine) in\n",
      "\n",
      "the OpenAI web client.\n",
      "\n",
      "20\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 5: Default system message for the built-in assistant agent in AutoGen (v0.1.1). This is\n",
      "an example of conversation programming via natural language. It contains instructions of\n",
      "different types, including role play, control flow, output confine, facilitate automation, and\n",
      "grounding.\n",
      "\n",
      "• ChatGPT+Code Interpreter: This is a recent feature in OpenAI web client. Note that the\n",
      "above two premium features from ChatGPT require a paid subscription to be accessed\n",
      "and are the most competitive commercial systems.\n",
      "\n",
      "• LangChain ReAct+Python: We use Python agent from LangChain. To handle parsing\n",
      "errors, we set “handle parsing errors=True”, and use the default zero-shot ReAct prompt.\n",
      "• Multi-Agent Debate (Liang et al., 2023): We modified the code of the multi-agent debate\n",
      "to perform evaluation. By default, there are three agents: an affirmative agent, a negative\n",
      "agent, and a moderator.\n",
      "\n",
      "We also conducted preliminary evaluations on several other multi-agent systems, including\n",
      "BabyAGI, CAMEL, and MetaGPT. The results indicate that they are not suitable choices for\n",
      "solving math problems out of the box. For instance, when MetaGPT is tasked with solving a\n",
      "math problem, it begins developing software to address the problem, but most of the time,\n",
      "it does not actually solve the problem. We have included the test examples in Appendix F.\n",
      "For the qualitative evaluation, we utilize two level-5 problems from the MATH dataset,\n",
      "testing each problem three times. The first problem involves simplifying a square root\n",
      "fraction, and the second problem involves solving a number theory issue. The correctness\n",
      "counts and reasons for failure are detailed in Table 1. For the quantitative evaluation, we\n",
      "conduct two sets of experiments on the MATH dataset to assess the correctness of these\n",
      "systems: (1) an experiment involving 120 level-5 (the most challenging level) problems,\n",
      "including 20 problems from six categories, excluding geometry, and (2) an experiment on\n",
      "the entire test set, which includes 5000 problems. We exclude AutoGPT from this evaluation\n",
      "\n",
      "21\n",
      "\n",
      "SystemMessageYou are a helpful AI assistant. Solve tasks using your coding and language skills.In the following cases, suggest python code (in a python coding block) or shell script (in a shcoding block) for the user to execute.1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.2. When you need to perform some task with code, use the code to perform the task and output theresult. Finish the task smartly.Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can’t modify your code. So do not suggest incomplete code which requires users to modify. Don’t use a code block if it’s not intended to be executed by the user.If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don’t include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use ’print’ function for the output when relevant. Check the execution result returned by the user.If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can’t be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.Reply “TERMINATE” in the end when everything is done.Prompting techniques color code: Role Play; Control Flow; Output Confine; Facilitate Automation; Grounding\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 6: Illustration of three problem-solving scenarios with AutoGen: (Gray) Enables a\n",
      "workflow where a student collaborates with an assistant agent to solve problems, either\n",
      "autonomously or in a human-in-the-loop mode. (Gray + Orange) Facilitates a more so-\n",
      "phisticated workflow wherein the assistant, on the fly, can engage another user termed\n",
      "“expert”, who is in the loop with their own assistant agent, to aid in problem-solving if its\n",
      "own solutions are not satisfactory.\n",
      "\n",
      "as it cannot access results from code executions and does not solve any problems in the\n",
      "qualitative evaluation. Our analysis of the entire dataset reveals that AutoGen achieves an\n",
      "overall accuracy of 69.48%, while GPT-4’s accuracy stands at 55.18%. From these evaluations,\n",
      "we have the following observations regarding the problem-solving success rate and user\n",
      "experience of these systems:\n",
      "\n",
      "• Problem-solving success rate: Results from the quantitative evaluations show that\n",
      "AutoGen can help achieve the highest problem-solving success rate among all the com-\n",
      "pared methods. The qualitative evaluations elucidate common failure reasons across\n",
      "several alternative approaches. ChatGPT+Code Interpreter fails to solve the second\n",
      "problem, and ChatGPT+Plugin struggles to solve both problems. AutoGPT fails on both\n",
      "problems due to code execution issues. The LangChain agent also fails on both problems,\n",
      "producing code that results in incorrect answers in all trials.\n",
      "\n",
      "• Based on the qualitative evaluation, we analyze the user experience concerning the ver-\n",
      "bosity of the response and the ability of the LLM-based system to run without unexpected\n",
      "behaviors. ChatGPT+Plugin is the least verbose, mainly because Wolfram queries are\n",
      "much shorter than Python code. AutoGen, ChatGPT+Code Interpreter, and LangChain\n",
      "exhibit similar verbosity, although LangChain is slightly more verbose due to more code\n",
      "execution errors. AutoGPT is the most verbose system owing to predefined steps like\n",
      "THOUGHTS, REASONING, and PLAN, which it includes in replies every time. Over-\n",
      "all, AutoGen and ChatGPT+Code Interpreter operate smoothly without exceptions. We\n",
      "note the occurrences of undesired behaviors from other LLM-based systems that could\n",
      "affect user experience: AutoGPT consistently outputs code without the print’ statement\n",
      "and cannot correct this, requiring the user to run them manually; ChatGPT with Wol-\n",
      "fram Alpha plugin has the potential to become stuck in a loop that must be manually\n",
      "stopped; and Langchain ReAct could exit with a parse error, necessitating the passing of\n",
      "a ‘handle parse error’ parameter.\n",
      "\n",
      "Scenario 2: Human-in-the-loop Problem Solving. For challenging problems that these\n",
      "LLM systems cannot solve autonomously, human feedback during the problem-solving\n",
      "process can be helpful. To incorporate human feedback with AutoGen, one can set\n",
      "\n",
      "22\n",
      "\n",
      "Enable Multi-User Problem Solving ViaStudent        and Expert Student ProxyStudentAssistantExpertAssistantExpert ProxyAsk for expertEnable Autonomous and Human-in-the-loop Problem Solving\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 1: Qualitative evaluation of two math problems from the MATH dataset within the\n",
      "autonomous problem-solving scenario. Each LLM-based system is tested three times on\n",
      "each of the problems. This table reports the problem-solving correctness and summarizes\n",
      "the reasons for failure.\n",
      "\n",
      "AutoGen\n",
      "AutoGPT\n",
      "\n",
      "ChatGPT+Plugin\n",
      "\n",
      "Inter-\n",
      "\n",
      "ChatGPT+Code\n",
      "preter\n",
      "LangChain ReAct\n",
      "Multi-Agent Debate\n",
      "\n",
      "Correctness\n",
      "\n",
      "3/3\n",
      "0/3\n",
      "\n",
      "1/3\n",
      "\n",
      "2/3\n",
      "\n",
      "0/3\n",
      "0/3\n",
      "\n",
      "Failure Reason\n",
      "\n",
      "N/A.\n",
      "\n",
      "The LLM gives code without the print function so the\n",
      "\n",
      "result is not printed.\n",
      "\n",
      "The return from Wolfram Alpha contains 2 simplified\n",
      "\n",
      "results, including the correct answer, but GPT-4\n",
      "\n",
      "always chooses the wrong answer.\n",
      "Returns a wrong decimal result.\n",
      "\n",
      "LangChain gives 3 different wrong answers.\n",
      "\n",
      "It gives 3 different wrong answers due to calculation\n",
      "\n",
      "errors.\n",
      "\n",
      "(a) Evaluation on the first problem that asks to simplify a square root fraction.\n",
      "\n",
      "AutoGen\n",
      "AutoGPT\n",
      "\n",
      "ChatGPT+Plugin\n",
      "\n",
      "Inter-\n",
      "\n",
      "ChatGPT+Code\n",
      "preter\n",
      "LangChain ReAct\n",
      "Multi-Agent Debate\n",
      "\n",
      "Correctness\n",
      "\n",
      "2/3\n",
      "0/3\n",
      "\n",
      "1/3\n",
      "\n",
      "0/3\n",
      "\n",
      "0/3\n",
      "0/3\n",
      "\n",
      "Failure Reason\n",
      "\n",
      "The final answer from code execution is wrong.\n",
      "\n",
      "The LLM gives code without the print function so the\n",
      "\n",
      "result is not printed.\n",
      "\n",
      "For one trial, GPT-4 got stuck because it keeps giving\n",
      "wrong queries and has to be stopped. Another trial\n",
      "\n",
      "simply gives a wrong answer.\n",
      "\n",
      "It gives 3 different wrong answers.\n",
      "\n",
      "LangChain gives 3 different wrong answers.\n",
      "\n",
      "It gives 3 different wrong answers.\n",
      "\n",
      "(b) Evaluation on the second number theory problem.\n",
      "\n",
      "human input mode=‘ALWAYS’ in the user proxy agent. We select one challenging problem\n",
      "that none of these systems can solve autonomously across three trials. We adhere to the\n",
      "process outlined below to provide human inputs for all the compared methods:\n",
      "\n",
      "1. Input the problem: Find the equation of the plane which bisects the angle\n",
      "between the planes 3x − 6y + 2z + 5 = 0 and 4x − 12y + 3z − 3 = 0, and which\n",
      "contains the point (−5,−1,−5). Enter your answer in the form\n",
      "\n",
      "Ax + By + Cz + D = 0,\n",
      "\n",
      "where A, B, C, D are integers such that A > 0 and gcd(|A|,|B|,|C|,|D|) = 1.\n",
      "2. The response from the system does not solve the problem correctly. We then give\n",
      "a hint to the model: Your idea is not correct. Let’s solve this together.\n",
      "Suppose P = (x, y, z) is a point that lies on a plane that bisects the angle,\n",
      "the distance from P to the two planes is the same. Please set up this\n",
      "equation first.\n",
      "\n",
      "3. We expect the system to give the correct distance equation. Since the equation\n",
      "involves an absolute sign that is hard to solve, we would give the next hint: Consider\n",
      "the two cases to remove the abs sign and get two possible solutions.\n",
      "\n",
      "4. If the system returns the two possible solutions and doesn’t continue to the next\n",
      "step, we give the last hint: Use point (-5,-1,-5) to determine which is correct\n",
      "and give the final answer.\n",
      "\n",
      "5. Final answer is 11x+6y+5z+86=0 .\n",
      "\n",
      "We observed that AutoGen consistently solved the problem across all three trials. Chat-\n",
      "GPT+Code Interpreter and ChatGPT+Plugin managed to solve the problem in two out\n",
      "\n",
      "23\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "of three trials, while AutoGPT failed to solve it in all three attempts. In its unsuccessful\n",
      "attempt, ChatGPT+Code Interpreter failed to adhere to human hints. In its failed trial,\n",
      "ChatGPT+Plugin produced an almost correct solution but had a sign discrepancy in the\n",
      "final answer. AutoGPT was unable to yield a correct solution in any of the trials. In one\n",
      "trial, it derived an incorrect distance equation. In the other two trials, the final answer was\n",
      "incorrect due to code execution errors.\n",
      "\n",
      "Scenario 3: Multi-User Problem Solving. Next-generation LLM applications may neces-\n",
      "sitate the involvement of multiple real users for collectively solving a problem with the\n",
      "assistance of LLMs. We showcase how AutoGen can be leveraged to effortlessly construct\n",
      "such a system. Specifically, building upon scenario 2 mentioned above, we aim to devise a\n",
      "simple system involving two human users: a student and an expert. In this setup, the stu-\n",
      "dent interacts with an LLM assistant to address some problems, and the LLM automatically\n",
      "resorts to the expert when necessary.\n",
      "The overall workflow is as follows: The student chats with the LLM-based assistant agent\n",
      "through a student proxy agent to solve problems. When the assistant cannot solve the\n",
      "problem satisfactorily, or the solution does not match the expectation of the student, it\n",
      "would automatically hold the conversation and call the pre-defined ask for expert function\n",
      "via the function call feature of LLM in order to resort to the expert. Specifically, it would\n",
      "automatically produce the initial message for the ask for expert function, which could be\n",
      "the statement of the problem or the request to verify the solution to a problem, and the\n",
      "expert is supposed to respond to this message with the help of the expert assistant. After\n",
      "the conversation between the expert and the expert’s assistant, the final message would be\n",
      "sent back to the student assistant as the response to the initial message. Then, the student\n",
      "assistant would resume the conversation with the student using the response from the\n",
      "expert for a better solution. A detailed visualization is shown in Figure 6.\n",
      "With AutoGen, constructing the student/expert proxy agent and the assistant agents is\n",
      "straightforward by reusing the built-in UserProxyAgent and AssistantAgent through ap-\n",
      "propriate configurations. The only development required involves writing several lines of\n",
      "code for the ask for expert function, which then becomes part of the configuration for the\n",
      "assistant. Additionally, it’s easy to extend such a system to include more than one expert,\n",
      "with a specific ask for expert function for each, or to include multiple student users with a\n",
      "shared expert for consultation.\n",
      "\n",
      "24\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A2: Retrieval-Augmented Q&A\n",
      "\n",
      "Figure 7: Overview of RAG Chat which involves two agents, including a RAG User Proxy\n",
      "and a Retrieval-augmented Assistant. Given a set of documents, the Retrieval-augmented\n",
      "User Proxy first automatically processes documents—splits, chunks, and stores them in a\n",
      "vector database. Then for a given user input, it retrieves relevant chunks as context and\n",
      "sends it to the Retrieval-augmented Assistant, which uses LLM to generate code or text to\n",
      "answer questions. Agents converse until they find a satisfactory answer.\n",
      "\n",
      "Detailed Workflow. The workflow of RAG Chat is illustrated in Figure 7. To use Retrieval-\n",
      "augmented Chat, one needs to initialize two agents including Retrieval-augmented User\n",
      "Proxy and Retrieval-augmented Assistant. Initializing the Retrieval-Augmented User Proxy\n",
      "necessitates specifying a path to the document collection. Subsequently, the Retrieval-\n",
      "Augmented User Proxy can download the documents, segment them into chunks of a\n",
      "specific size, compute embeddings, and store them in a vector database. Once a chat\n",
      "is initiated, the agents collaboratively engage in code generation or question-answering\n",
      "adhering to the procedures outlined below:\n",
      "1. The Retrieval-Augmented User Proxy retrieves document chunks based on the embed-\n",
      "ding similarity, and sends them along with the question to the Retrieval-Augmented\n",
      "Assistant.\n",
      "\n",
      "2. The Retrieval-Augmented Assistant employs an LLM to generate code or text as answers\n",
      "based on the question and context provided. If the LLM is unable to produce a satisfactory\n",
      "response, it is instructed to reply with “Update Context” to the Retrieval-Augmented\n",
      "User Proxy.\n",
      "\n",
      "3. If a response includes code blocks, the Retrieval-Augmented User Proxy executes the\n",
      "code and sends the output as feedback. If there are no code blocks or instructions to\n",
      "update the context, it terminates the conversation. Otherwise, it updates the context and\n",
      "forwards the question along with the new context to the Retrieval-Augmented Assistant.\n",
      "Note that if human input solicitation is enabled, individuals can proactively send any\n",
      "feedback, including “Update Context”, to the Retrieval-Augmented Assistant.\n",
      "\n",
      "4. If the Retrieval-Augmented Assistant receives “Update Context”, it requests the next\n",
      "most similar chunks of documents as new context from the Retrieval-Augmented User\n",
      "Proxy. Otherwise, it generates new code or text based on the feedback and chat history. If\n",
      "the LLM fails to generate an answer, it replies with “Update Context” again. This process\n",
      "can be repeated several times. The conversation terminates if no more documents are\n",
      "available for the context.\n",
      "\n",
      "We utilize Retrieval-Augmented Chat in two scenarios. The first scenario aids in generating\n",
      "code based on a given codebase. While LLMs possess strong coding abilities, they are\n",
      "unable to utilize packages or APIs that are not included in their training data, e.g., private\n",
      "codebases, or have trouble using trained ones that are frequently updated post-training.\n",
      "Hence, Retrieval-Augmented Code Generation is considered to be highly valuable. The sec-\n",
      "ond scenario involves question-answering on the Natural Questions dataset (Kwiatkowski\n",
      "et al., 2019), enabling us to obtain comparative evaluation metrics for the performance of\n",
      "our system.\n",
      "Scenario 1: Evaluation on Natural Questions QA dataset. In this case, we evaluate the\n",
      "Retrieval-Augmented Chat’s end-to-end question-answering performance using the Natural\n",
      "\n",
      "25\n",
      "\n",
      "Retrieval-augmentedAssistantRetrieval-augmented  User Proxy1. Question and Contexts3. Terminate,feedbacks or `Update Context`4. Satisfied Answers or Terminate2. Satisfied Answers or `Update Context`\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 8: Retrieval-augmented Chat without (W/O) and with (W/) interactive retrieval.\n",
      "\n",
      "Questions dataset (Kwiatkowski et al., 2019). We collected 5,332 non-redundant context\n",
      "documents and 6,775 queries from HuggingFace. First, we create a document collection\n",
      "based on the entire context corpus and store it in the vector database. Then, we utilize\n",
      "Retrieval-Augmented Chat to answer the questions. An example (Figure 8) from the NQ\n",
      "dataset showcases the advantages of the interactive retrieval feature: “who carried the usa\n",
      "flag in opening ceremony”. When attempting to answer this question, the context with the\n",
      "highest similarity to the question embedding does not contain the required information for\n",
      "a response. As a result, the LLM assistant (GPT-3.5-turbo) replies “Sorry, I cannot find any\n",
      "information about who carried the USA flag in the opening ceremony. UPDATE CONTEXT.” With\n",
      "the unique and innovative ability to update context in Retrieval-Augmented Chat, the user\n",
      "proxy agent automatically updates the context and forwards it to the assistant agent again.\n",
      "Following this process, the agent is able to generate the correct answer to the question.\n",
      "In addition, we conduct an experiment using the same prompt as illustrated in (Adlakha\n",
      "et al., 2023) to investigate the advantages of AutoGen W/O interactive retrieval. The F1 score\n",
      "and Recall for the first 500 questions are 23.40% and 62.60%, respectively, aligning closely\n",
      "with the results reported in Figure 4b. Consequently, we assert that AutoGen W/O interac-\n",
      "tive retrieval outperforms DPR due to differences in the retrievers employed. Specifically,\n",
      "we utilize a straightforward vector search retriever with the all-MiniLM-L6-v2 model for\n",
      "embeddings.\n",
      "Furthermore, we analyze the number of LLM calls in experiments involving both AutoGen\n",
      "and AutoGen W/O interactive retrieval, revealing that approximately 19.4% of questions in the\n",
      "Natural Questions dataset trigger an “Update Context” operation, resulting in additional\n",
      "LLM calls.\n",
      "Scenario 2: Code Generation Leveraging Latest APIs from the Codebase. In this case,\n",
      "the question is “How can I use FLAML to perform a classification task and use Spark for parallel\n",
      "training? Train for 30 seconds and force cancel jobs if the time limit is reached.”. FLAML (v1) (Wang\n",
      "et al., 2021) is an open-source Python library designed for efficient AutoML and tuning. It\n",
      "was open-sourced in December 2020, and is included in the training data of GPT-4. However,\n",
      "the question necessitates the use of Spark-related APIs, which were added in December\n",
      "2022 and are not encompassed in the GPT-4 training data1. Consequently, the original\n",
      "GPT-4 model is unable to generate the correct code, due to its lack of knowledge regarding\n",
      "Spark-related APIs. Instead, it erroneously creates a non-existent parameter, spark, and sets\n",
      "it to True’. Nevertheless, with Retrieval-Augmented Chat, we provide the latest reference\n",
      "documents as context. Then, GPT-4 generates the correct code blocks by setting use spark\n",
      "and f orce cancel to True’.\n",
      "\n",
      "1gpt-4-0613 is used in this experiment. Its cutoff date is September 2021.\n",
      "\n",
      "26\n",
      "\n",
      "Task description who carried the usaflag in opening ceremony?UserProxy: You’re a retrieve augmented chatbot. You answer user’s questions based on your own knowledge and the context provided by the user. If you can’t answer the question with or without the current context, you should reply exactly ‘UPDATE CONTEXT’. You must give as short an answer as possible.User’s question is:who carried the usaflag in opening ceremonyContext is: < P > On January 17 , 1899 , under ... The Astros beat the Yankees that night , 2 -1 . < /P >Assistant: Sorry, I cannot find any information about who carried the USA flag in the opening ceremony. UPDATE CONTEXT.UserProxy: You’re a retrieve augmented chatbot. You answer user’s questions based on your own knowledge and the context provided by the user. If you can’t answer the question with or without the current context, you should reply exactly ‘UPDATE CONTEXT’. You must give as short an answer as possible.User’s question is:who carried the usaflag in opening ceremonyContext is: < T able > ... Erin Hamlin ... < /T d >Assistant: Erin Hamlin carried the USA flag in the opening ceremony. (a) W/O Interactive Retrieval(b) W/ Interactive RetrievalUserProxy: You’re a retrieve augmented chatbot. You answer user’s questions based on your own knowledge and the context provided by the user. If you can’t answer the question with or without the current context, you should reply ‘sorry, I don’t know’. You must give as short an answer as possible.User’s question is:who carried the usaflag in opening ceremonyContext is: < P > On January 17 , 1899 , under ... The Astros beat the Yankees that night , 2 -1 . < /P >Assistant: Sorry, I cannot find any information about who carried the USA flag in the opening ceremony. Sorry, I don’t know.\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A3: Decision Making in Embodied Agents\n",
      "\n",
      "Figure 9: Overview of two versions of ALFChat: a two-agent approach where an assistant\n",
      "agent proposes the subsequent step and an executor carries out actions while providing\n",
      "feedback, and a three-agent design that incorporates a grounding agent to furnish the\n",
      "executor with commonsense facts when required.\n",
      "\n",
      "ALFWorld (Shridhar et al., 2021) is a synthetic language-based interactive decision-making\n",
      "task. It comprises textual environments that aim to simulate real-world household scenes.\n",
      "Given a high-level goal (e.g., putting a hot apple in the fridge) and the description of\n",
      "the household environment, the agent needs to explore and interact with the simulated\n",
      "household environment through a textual interface. A typical task environment contains\n",
      "various types of locations and could require more than 40 steps to finish, which requires\n",
      "agents to decompose the goal into subtasks and tackle them one by one, while effectively\n",
      "exploring the environments.\n",
      "Detailed Workflow. We first propose a straightforward two-agent system with AutoGen,\n",
      "illustrated on the left-hand side of Figure 9, to tackle tasks from this benchmark. The system\n",
      "consists of an assistant agent and an executor agent. The assistant agent generates plans\n",
      "and makes action decisions to solve the tasks. The executor agent is tailored specifically\n",
      "for ALFWorld. It performs actions proposed by the assistant and reports action execution\n",
      "results in the household environment as feedback to the assistant. Due to the strict format\n",
      "requirements for the output format, we use the BLEU metric to evaluate the similarity of\n",
      "the output to all valid action options. The option with the highest similarity will be chosen\n",
      "as the action for this round.\n",
      "A significant challenge encompassed in ALFWorld involves commonsense reasoning. The\n",
      "agent needs to extract patterns from the few-shot examples provided and combine them\n",
      "with the agent’s general knowledge of household environments to fully understand task\n",
      "rules. More often than not, the assistant tends to neglect some basic knowledge of the\n",
      "household environment. Thanks to the easy-to-implement multi-agent conversational\n",
      "feature of AutoGen, enhancing the assistant agent’s reasoning ability by adding a new\n",
      "grounding agent to provide commonsense facts for the decision-making agent’s reference\n",
      "becomes straightforward. By scrutinizing the failed attempts and summarizing the reasons\n",
      "for failure, we obtained a holistic understanding of the commonsense knowledge that the\n",
      "assistant agent lacks. Then, we set a grounding agent to provide this general knowledge\n",
      "when the task begins and whenever the assistant outputs the same action three times in a\n",
      "row. This ensures the assistant takes this commonsense knowledge into consideration.\n",
      "We compare our system’s performance with ReAct. ReAct (Yao et al., 2022) is a few-shot\n",
      "prompting technique that interleaves reasoning and acting, allowing for greater synergy\n",
      "between the two and significantly improving performance on both language and decision-\n",
      "making tasks. We integrate ReAct into AutoGen by modifying the prompts into a conver-\n",
      "\n",
      "27\n",
      "\n",
      "ALFWorldExecutorReward & StateAction DecisionAssistantObservation: On the desk 2, you see an alarmclock3, a bowl 3, a creditcard2, a mug 1, and a pencil 2.Action decision: Pick up pencil 2 from desk 2GroundingAgentALFChat(two agents)ALFChat(three agents)ALFWorldExecutorAssistant\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 10: Comparison of results from two designs: (a) two-agent design, which consists of\n",
      "an assistant and an executor, and (b) three-agent design, which adds a grounding agent that\n",
      "serves as a knowledge source. For simplicity, we omit the in-context examples and part of\n",
      "the exploration trajectory, and only show parts contributing to the failure/success of the\n",
      "attempt.\n",
      "\n",
      "sational manner. Following ReAct, we employ a two-shot setting. The few-shot prompts\n",
      "are obtained from the corresponding repository. As shown in Table 2, the two-agent design\n",
      "matches the performance of ReAct, while the three-agent design significantly outperforms\n",
      "ReAct. On the other hand, introducing a grounding agent as a knowledge source remarkably\n",
      "advances performance on all types of tasks.\n",
      "Case study. Figure 10 exemplifies how a three-agent design eliminates one root cause for\n",
      "failure cases. Most of the tasks involve taking an object and then performing a specific action\n",
      "with it (e.g., finding a vase and placing it on a cupboard). Without a grounding agent, the\n",
      "assistant frequently conflates finding an object with taking it, as illustrated in Figure 10(a).\n",
      "This leads to most of the failure cases in ’pick’ and ’look’ type tasks. With the introduction\n",
      "of a grounding agent, the assistant can break this loop and successfully complete the task.\n",
      "Takeaways. We introduced a grounding agent to serve as an external commonsense knowl-\n",
      "edge source, which significantly enhanced the assistant’s ability to make informed decisions.\n",
      "This proves that providing necessary commonsense facts to the decision-making agent can\n",
      "assist it in making more informed decisions, thus effectively boosting the task success rate.\n",
      "AutoGen brings both simplicity and modularity when adding the grounding agent.\n",
      "\n",
      "Method\n",
      "\n",
      "ReAct (avg)\n",
      "\n",
      "ALFChat (2 agents)(avg)\n",
      "ALFChat (3 agents)(avg)\n",
      "\n",
      "ReAct (best of 3)\n",
      "\n",
      "ALFChat (2 agents)(best of 3)\n",
      "ALFChat (3 agents)(best of 3)\n",
      "\n",
      "Pick Clean Heat Cool Look Pick 2 All\n",
      "54\n",
      "63\n",
      "54\n",
      "61\n",
      "69\n",
      "79\n",
      "75\n",
      "66\n",
      "63\n",
      "71\n",
      "92\n",
      "77\n",
      "\n",
      "48\n",
      "57\n",
      "70\n",
      "61\n",
      "65\n",
      "78\n",
      "\n",
      "71\n",
      "67\n",
      "76\n",
      "81\n",
      "76\n",
      "86\n",
      "\n",
      "61\n",
      "50\n",
      "78\n",
      "78\n",
      "67\n",
      "83\n",
      "\n",
      "52\n",
      "58\n",
      "64\n",
      "62\n",
      "61\n",
      "74\n",
      "\n",
      "24\n",
      "19\n",
      "41\n",
      "35\n",
      "35\n",
      "41\n",
      "\n",
      "Table 2: Comparisons between ReAct and the two versions of ALFChat. For each task,\n",
      "we report the success rate out of 3 attempts. Success rate denotes the number of tasks\n",
      "successfully completed by the agent divided by the total number of tasks. The results show\n",
      "that adding a grounding agent significantly improves the task success rate in ALFChat.\n",
      "\n",
      "28\n",
      "\n",
      "Task descriptionYou are in the middle of a room. Looking quickly around you, you see a bed 1, a desk 2, a desk 1, a safe 1, a drawer 2, a drawer1, a shelf 3, a shelf 2, and a shelf 1.Your task is to: look at bowl under the desklamp. Assistant(to Executor): THOUGHT [First, I need to find a bowl. A bowl is more likely to appear in desk (1-2), drawer (1-2), shelf (1-3), bed (1). Then I need to find and use a desklamp.] ACTION [go to desk 1](Assistant finds the desklampat desk 1, then goes to desk 2.)Executor(to Assistant): On the desk 2, you see a bowl 1, and a cd 3... Assistant(to Executor): THOUGHT [Now I find a bowl (1). I need to use the desklampto look at the bowl. I'll go to the desklampnow.] ACTION [go to desk 1]Executor(to Assistant):On the desk 1, you see a desklamp1, a pencil 2...Assistant: ACTION [use desklamp1]Executor(to Assistant): You turn on the desklamp1.Assistant(to Executor):THOUGHT [Now that the desklampis turned on, I can use it to look at the bowl (1) that I found earlier.] ACTION [look at bowl 1 under the desklamp1]Executor(to Assistant): You turn on the desklamp1.(Assistant falls into an infinite loop turning on desklamp.)Executor(to Assistant): Task failed. Reply TERMINATE.Assistant(to Executor): TERMINATEAssistant(to Executor): THOUGHT [First, I need to find a bowl. A bowl is more likely to appear in desk (1-2), drawer (1-2), shelf (1-3), bed (1). Then I need to find and use a desklamp.] ACTION [go to desk 1](Assistant finds the desklampat desk 1, then goes to desk 2.)(Assistant falls into the same loop as (a))GroundingAgent(to Executor): You must find and take the object before you can examine it. You must go to where the target object is before you can use it.Executor(to Assistant): You turn on the desklamp1. Hint: You must find and take the object before you can examine it. Assistant(to Executor): THOUGHT [I need to find and take the bowl (1) before I can examine it. Let me find the bowl first.] ACTION [go to desk 2]Executor(to Assistant): On the desk 2, you see a bowl 1, a cd 3...Assistant(to Executor): ACTION [take bowl 1 from desk 2]Executor(to Assistant): You pick up bowl 1 from desk 2.Assistant(to Executor):ACTION [go to desk 1]Assistant(to Executor):ACTION[use desklamp1]Executor(to Assistant): Task success. Reply TERMINATE.Assistant(to Executor): TERMINATE(a) Two agents(b) Three agents\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A4: Supply-Chain Optimization\n",
      "\n",
      "Figure 11: Our re-implementation of OptiGuide with AutoGen streamlining agents’ interac-\n",
      "tions. The Commander receives user questions (e.g., What if we prohibit shipping from\n",
      "supplier 1 to roastery 2?) and coordinates with the Writer and Safeguard. The Writer crafts\n",
      "the code and interpretation, the Safeguard ensures safety (e.g., not leaking information, no\n",
      "malicious code), and the Commander executes the code. If issues arise, the process can\n",
      "repeat until resolved. Shaded circles represent steps that may be repeated multiple times.\n",
      "\n",
      "and\n",
      "\n",
      "Detailed Workflow. The workflow can be described as follows. The end user initiates\n",
      "the interaction by posing a question, such as “What if we prohibit shipping from supplier\n",
      "1 to roastery 2?”, marked by\n",
      "to the Commander agent. The Commander manages and\n",
      "coordinates with two LLM-based assistant agents: the Writer and the Safeguard. Apart from\n",
      "directing the flow of communication, the Commander has the responsibility of handling\n",
      "memory tied to user interactions. This capability enables the Commander to capture and\n",
      "retain valuable context regarding the user’s questions and their corresponding responses.\n",
      "Such memory is subsequently shared across the system, empowering the other agents with\n",
      "context from prior user interactions and ensuring more informed and relevant responses.\n",
      "In this orchestrated process, the Writer, who combines the functions of a “Coder” and an\n",
      "“Interpreter” as defined in Li et al. (2023a), will craft code and also interpret execution\n",
      "output logs. For instance, during code writing (\n",
      "), the Writer may craft code\n",
      "“model.addConstr(x[‘supplier1’, ‘roastery2’] == 0, ‘prohibit’)” to add an additional constraint\n",
      "to answer the user’s question.\n",
      "After receiving the code, the Commander will communicate with the Safeguard to screen\n",
      "the code and ascertain its safety (\n",
      "); once the code obtains the Safeguard’s clearance,\n",
      "marked by\n",
      ", the Commander will use external tools (e.g., Python) to execute the code and\n",
      "request the Writer to interpret the execution results for the user’s question (\n",
      "and ). For\n",
      "instance, the writer may say “if we prohibit shipping from supplier 1 to roastery 2, the total\n",
      "cost would increase by 10.5%.” Bringing this intricate process full circle, the Commander\n",
      "furnishes the user with the concluding answer (\n",
      "If at a point there is an exception - either a security red flag raised by Safeguard (in\n",
      ")\n",
      "or code execution failures within Commander, the Commander redirects the issue back\n",
      "to the Writer with essential information in logs (\n",
      "). So, the process from to might\n",
      "be repeated multiple times, until each user query receives a thorough and satisfactory\n",
      "resolution or until the timeout. This entire complex workflow of multi-agent interaction is\n",
      "elegantly managed via AutoGen.\n",
      "The core workflow code for OptiGuide was reduced from over 430 lines to 100 lines using\n",
      "AutoGen, leading to significant productivity improvement. The new agents are customizable,\n",
      "conversable, and can autonomously manage their chat memories. This consolidation allows\n",
      "\n",
      ").\n",
      "\n",
      "29\n",
      "\n",
      "CommanderSafeguardWriter②Question, ❻Log❸Code, ⑦Ans❹Code❺ClearanceUser①User Question⑧Final AnswerRepeat until answering the user’s question or timeout123456785636\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "the coder and interpreter roles to merge into a single “Writer” agent, resulting in a clean,\n",
      "concise, and intuitive implementation that is easier to maintain.\n",
      "\n",
      "Manual Evaluation Comparing ChatGPT + Code Interpreter and AutoGen-based OptiGu-\n",
      "ide. ChatGPT + Code Interpreter is unable to execute code with private or customized\n",
      "dependencies (e.g., Gurobi), which means users must have the engineering expertise to\n",
      "manually handle multiple steps. This disrupts the workflow and increases the chance\n",
      "for mistakes. If users lack access or expertise, the burden falls on supporting engineers,\n",
      "increasing their on-call time.\n",
      "We carried out a user study that juxtaposed OpenAI’s ChatGPT coupled with a Code\n",
      "Interpreter against AutoGen-based OptiGuide. The study focused on a coffee supply chain\n",
      "scenario, and an expert Python programmer with proficiency in Gurobi participated in the\n",
      "test. We evaluated both systems based on 10 randomly selected questions, measuring time\n",
      "and accuracy. While both systems answered 8 questions correctly, the Code Interpreter was\n",
      "significantly slower than OptiGuide because the former requires more manual intervention.\n",
      "On average, users needed to spend 4 minutes and 35 seconds to solve problems with the\n",
      "Code Interpreter, with a standard deviation of approximately 2.5 minutes. In contrast,\n",
      "OptiGuide’s average problem-solving time was around 1.5 minutes, most of which was\n",
      "spent waiting for responses from the GPT-4 model. This indicates a 3x saving on the user’s\n",
      "time with AutoGen-based OptiGuide.\n",
      "While using ChatGPT + Code Interpreter, users had to read through the code and instruc-\n",
      "tions to know where to paste the code snippets. Additionally, running the code involves\n",
      "downloading it and executing it in a terminal, a process that was both time-consuming and\n",
      "prone to errors. The response time from the Code Interpreter is also slower, as it generates\n",
      "lots of tokens to read the code, read the variables line-by-line, perform chains of thought\n",
      "analysis, and then produce the final answer code. In contrast, AutoGen integrates multiple\n",
      "agents to reduce user interactions by 3 - 5 times on average as reported in Table 3, where we\n",
      "evaluated our system with 2000 questions across five OptiGuide applications and measured\n",
      "how many prompts the user needs to type.\n",
      "\n",
      "Table 3: Manual effort saved with OptiGuide (W/ GPT-4) while preserving the same coding\n",
      "performance is shown in the data below. The data include both the mean and standard\n",
      "deviations (indicated in parentheses).\n",
      "\n",
      "Dataset\n",
      "Saving Ratio\n",
      "\n",
      "netflow\n",
      "\n",
      "facility\n",
      "\n",
      "tsp\n",
      "\n",
      "coffee\n",
      "\n",
      "diet\n",
      "\n",
      "3.14x (0.65)\n",
      "\n",
      "3.14x (0.64)\n",
      "\n",
      "4.88x (1.71)\n",
      "\n",
      "3.38x (0.86)\n",
      "\n",
      "3.03x (0.31)\n",
      "\n",
      "Table 12 and 14 provide a detailed comparison of user experience with ChatGPT+Code\n",
      "Interpreter and AutoGen-based OptiGuide. ChatGPT+Code Interpreter is unable to run\n",
      "code with private packages or customized dependencies; as a consequence, ChatGPT+Code\n",
      "Interpreter requires users to have engineering expertise and to manually handle multiple\n",
      "steps, disrupting the workflow and increasing the chance for mistakes. If customers lack\n",
      "access or expertise, the burden falls on supporting engineers, increasing their on-call time. In\n",
      "contrast, the automated chat by AutoGen is more streamlined and autonomous, integrating\n",
      "multiple agents to solve problems and address concerns. This results in a 5x reduction\n",
      "in interaction and fundamentally changes the overall usability of the system. A stable\n",
      "workflow can be potentially reused for other applications or to compose a larger one.\n",
      "\n",
      "Takeaways: The implementation of the multi-agent design with AutoGen in the OptiGuide\n",
      "application offers several advantages. It simplifies the Python implementation and fosters a\n",
      "mixture of collaborative and adversarial problem-solving environments, with the Comman-\n",
      "der and Writer working together while the Safeguard acts as a virtual adversarial checker.\n",
      "This setup allows for proper memory management, as the Commander maintains mem-\n",
      "ory related to user interactions, providing context-aware decision-making. Additionally,\n",
      "role-playing ensures that each agent’s memory remains isolated, preventing shortcuts and\n",
      "hallucinations\n",
      "\n",
      "30\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A5: Dynamic Group Chat\n",
      "\n",
      "Figure 12: Overview of how AutoGen enables dynamic group chats to solve tasks. The\n",
      "Manager agent, which is an instance of the GroupChatManager class, performs the following\n",
      "three steps–select a single speaker (in this case Bob), ask the speaker to respond, and\n",
      "broadcast the selected speaker’s message to all other agents\n",
      "\n",
      "To validate the necessity of multi-agent dynamic group chat and the effectiveness of the\n",
      "role-play speaker selection policy, we conducted a pilot study comparing a four-agent\n",
      "dynamic group chat system with two possible alternatives across 12 manually crafted\n",
      "complex tasks. An example task is “How much money would I earn if I bought 200 $AAPL\n",
      "stocks at the lowest price in the last 30 days and sold them at the highest price? Save the results\n",
      "into a file.” The four-agent group chat system comprised the following group members: a\n",
      "user proxy to take human inputs, an engineer to write code and fix bugs, a critic to review\n",
      "code and provide feedback, and a code executor for executing code. One of the possible\n",
      "alternatives is a two-agent system involving an LLM-based assistant and a user proxy agent,\n",
      "and another alternative is a group chat system with the same group members but a task-\n",
      "based speaker selection policy. In the task-based speaker selection policy, we simply append\n",
      "role information, chat history, and the next speaker’s task into a single prompt. Through\n",
      "the pilot study, we observed that compared with a task-style prompt, utilizing a role-play\n",
      "prompt in dynamic speaker selection often leads to more effective consideration of both\n",
      "conversation context and role alignment during the process of generating the subsequent\n",
      "speaker, and consequently a higher success rate as reported in Table 4, fewer LLM calls and\n",
      "fewer termination failures, as reported in Table 5.\n",
      "\n",
      "Table 4: Number of successes on the 12 tasks (higher the better).\n",
      "\n",
      "Model\n",
      "GPT-3.5-turbo\n",
      "GPT-4\n",
      "\n",
      "Two-agent Group chat Group Chat w/ task-based speaker selection\n",
      "\n",
      "8\n",
      "9\n",
      "\n",
      "9\n",
      "11\n",
      "\n",
      "7\n",
      "8\n",
      "\n",
      "Table 5: Average # LLM calls and number of termination failures on the 12 tasks (lower the\n",
      "better).\n",
      "\n",
      "Model\n",
      "GPT-3.5-turbo\n",
      "GPT-4\n",
      "\n",
      "Two-agent Group chat Group chat w/ task-based speaker selection\n",
      "\n",
      "9.9, 9\n",
      "6.8, 3\n",
      "\n",
      "5.3, 0\n",
      "4.5, 0\n",
      "\n",
      "4, 0\n",
      "4, 0\n",
      "\n",
      "31\n",
      "\n",
      "3. BroadcastAliceBobUser Proxy1. Select a Speaker AliceBobUser ProxyBob2. Ask the Speaker to RespondManagerManagerResponse\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Figure 13: Comparison of two-agent chat (a) and group chat (b) on a given task. The group\n",
      "chat resolves the task successfully with a smoother conversation, while the two-agent chat\n",
      "fails on the same task and ends with a repeated conversation.\n",
      "\n",
      "32\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A6: Conversational Chess\n",
      "\n",
      "Figure 14: Illustration of our conversational chess application. The application can support\n",
      "various scenarios, as each player can be an LLM-empowered AI, a human, or a hybrid of\n",
      "the two. Here, the board agent maintains the rules of the game and supports the players\n",
      "with information about the board. Players and the board agent all use natural language for\n",
      "communication.\n",
      "\n",
      "In Conversational Chess, each player is a AutoGen agent and can be powered either by a\n",
      "human or an AI. A third party, known as the board agent, is designed to provide players\n",
      "with information about the board and ensure that players’ moves adhere to legal chess\n",
      "moves. Figure 14 illustrates the scenarios supported by Conversational Chess: AI/human vs.\n",
      "AI/human, and demonstrates how players and the board agent interact. This setup fosters\n",
      "social interaction and allows players to express their moves creatively, employing jokes,\n",
      "meme references, and character-playing, thereby making chess games more entertaining for\n",
      "both players and observers (Figure 15 provides an example of conversational chess).\n",
      "To realize these scenarios, we constructed a player agent with LLM and human as back-end\n",
      "options. When human input is enabled, before sending the input to the board agent, it\n",
      "first prompts the human player to input the message that contains the move along with\n",
      "anything else the player wants to say (such as a witty comment). If human input is skipped\n",
      "or disabled, LLM is used to generate the message. The board agent is implemented with a\n",
      "custom reply function, which employs an LLM to parse the natural language input into a\n",
      "legal move in a structured format (e.g., UCI), and then pushes the move to the board. If the\n",
      "move is not legitimate, the board agent will reply with an error. Subsequently, the player\n",
      "agent needs to resend a message to the board agent until a legal move is made. Once the\n",
      "move is successfully pushed, the player agent sends the message to the opponent. As shown\n",
      "in Figure 15, the conversation between AI players can be natural and entertaining. When\n",
      "the player agent uses LLM to generate a message, it utilizes the board state and the error\n",
      "message from the board agent. This helps reduce the chance of hallucinating an invalid\n",
      "move. The chat between one player agent and the board agent is invisible to the other player\n",
      "agent, which helps keep the messages used in chat completion well-managed.\n",
      "There are two notable benefits of using AutoGen to implement Conversational Chess. Firstly,\n",
      "the agent design in AutoGen facilitates the natural creation of objects and their interactions\n",
      "needed in our chess game. This makes development easy and intuitive. For example, the\n",
      "isolation of chat messages simplifies the process of making a proper LLM chat completion\n",
      "inference call. Secondly, AutoGen greatly simplifies the implementation of agent behaviors\n",
      "using composition. Specifically, we utilized the register reply method supported by\n",
      "AutoGen agents to instantiate player agents and a board agent with custom reply functions.\n",
      "\n",
      "33\n",
      "\n",
      "Chess BoardHuman/AI Chess Player AHuman/AI Chess Player BValidate moveValidate moveChallenging your pawn in the center. Your move.Developing my knightto a good square.Your move.\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Concentrating the extension work needed at a single point (the reply function) simplifies\n",
      "the reasoning processes, and development and maintenance effort.\n",
      "\n",
      "(a) Conversation between two AI players\n",
      "\n",
      "(b) Conversation between the AI play-\n",
      "ers (player white shown in blue) and the\n",
      "board agent for making a new move.\n",
      "\n",
      "Figure 15: Example conversations during a game involving two AI player agents and a\n",
      "board agent.\n",
      "\n",
      "To illustrate the effect facilitated by this board agent, we provide a demonstration of con-\n",
      "versational chess without a board agent in Figure 16. In this demonstration, instead of\n",
      "employing an additional board agent for grounding, the system utilizes prompting for\n",
      "grounding by including the sentence “You should make sure both you and the opponent are\n",
      "making legal moves.” in the system messages directed to both players.\n",
      "\n",
      "Figure 16: Comparison of two designs in Conversational Chess: (a) without a board agent,\n",
      "and (b) with a board agent.\n",
      "\n",
      "34\n",
      "\n",
      "Alright, let's kick things off. I'll move my pawn from e2 to e4. The center of the board is the heart of the battle, isn't it?Ah, the King's Pawn Opening, a classic. Let's see how this plays out. I'll move my pawn from e7 to e5.You know, I've always admired how chess reflects life. It's all about making strategic decisions, isn't it? Your move.…Indeed, chess is a mirror of life in many ways. Every move matters, just like every decision in life. I'll move my knight from g1 to f3, aiming to control the center.Error: illegal uci: 'e4e5' in ...I'll move my pawn from d2 to d4, opening uplines for my queen and bishop.Indeed, the king's safety is paramount in the early game. Now, let's stir things up a bit. I'll move my pawn from e4 to e5, attacking your knight.System message to the player agents: Your name is {name} and you are a chess player. You are playing against{opponent_name}. You are playing as {color}. You communicate your move using universal chess interface language. You also chit-chat with your opponent when you communicate a move to light up the mood.You should make sure both you and the opponent are making legal moves...Player White: Your movePlayer black:Alright, let's start. I'll move my pawn from e7 to e5. Here's how the board looks now:r n b q k b n rp p p p . p p p. . . . . . . .. . . . p . . .. . . . . . . .. . . . . . . .P P P P P P P PR N B Q K B N RYour turn!Player White:Yes, it certainly is! Let's keep this up. I'll move my knight from b8 to c6. Here's the updated board:. n b q k b . rp p p p . p p p. . n . . n . .. . . . p . . .. . . . P . . .. . . . N . . .P P P P . P P PR N B Q K B . RYour move! You're giving me a tough time here.Conversational Chess(b) W/ Board Agent(a) W/O Board AgentPlayer White: Your movePlayer black:Alright, let's start. I'll move my pawn from e7 to e5. Here's how the board looks now:r n b q k b n rp p p p . p p p. . . . . . . .. . . . p . . .. . . . . . . .. . . . . . . .P P P P P P P PR N B Q K B N RYour turn!Player White:let's get my knight into the game. I'll move my knight to f3. So, g8f3. Your move.r . b q k b n rp p p p . p p p. . n . . n . .. . . . p . . .. . . . P . . .. . . . . . . .P P P P . P P PR N B Q K B N RBoard Agent:You've made a mistake, Player white. As you are playing white, your knight is on g1, not g8. Therefore, your move should be g1f3, not g8f3. Let's correct that.Player White:Couldn't agree more, the lessons we learn from chess apply to life as well. Here'sthe updated board:r . b q k b n rpppp. ppp. . n . . . . .. . . . p . . .. . . . P . . .. . . . . N . .PPPP. PPPR N B Q K B . R\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "A7: Online Decision Making in Web Interaction Tasks\n",
      "\n",
      "Figure 17: Overview of the proposed MiniWobChat. MiniWobChat consists of two agents: an\n",
      "assistant agent and an executor agent. The assistant agent suggests actions to manipulate the\n",
      "browser while the executor executes the suggested actions and returns rewards/feedback.\n",
      "The assistant agent records the feedback and continues until the feedback indicates task\n",
      "success or failure.\n",
      "\n",
      "In practice, many applications require the presence of agents capable of interacting with\n",
      "environments and making decisions in an online context, such as in game playing (Mnih\n",
      "et al., 2013; Vinyals et al., 2017), web interactions (Liu et al., 2018; Shi et al., 2017; Zhou\n",
      "et al., 2023; Koh et al., 2024), and embodied actions (Puig et al., 2018; Shen et al., 2021;\n",
      "Guo et al., 2024). With the multi-agent conversational framework in AutoGen, it becomes\n",
      "easy to decompose the automatic agent-environment interactions and the development\n",
      "of a decision-making agent by constructing an executor agent responsible for handling the\n",
      "interaction with the environment, thereby delegating the decision-making part to other\n",
      "agents. Such a decomposition allows developers to reuse the decision-making agent for\n",
      "new tasks with minimal effort rather than building a specialized decision-making agent for\n",
      "every new environment.\n",
      "\n",
      "Workflow. We demonstrate how to use AutoGen to build a working system for handling\n",
      "such scenarios with the MiniWoB++ benchmark (Shi et al., 2017). MiniWoB++ comprises\n",
      "browser interaction tasks that involve utilizing mouse and keyboard actions to interact with\n",
      "browsers. The ultimate objective of each task is to complete the tasks described concisely\n",
      "in natural language, such as “expand the web section below and click the submit button.”\n",
      "Solving these tasks typically requires a sequence of web manipulation actions rather than\n",
      "a single action, and making action decisions at each time step requires access to the web\n",
      "status (in the form of HTML code) online. For the example above, clicking the submit\n",
      "button requires checking the web status after expanding the web section. We designed\n",
      "a straightforward two-agent system named MiniWobChat using AutoGen, as shown in\n",
      "Figure 17. The assistant agent is an instance of the built-in AssistantAgent and is responsible\n",
      "for making action decisions for the given task. The second agent, the executor agent, is a\n",
      "customized UserProxyAgent, which is responsible for interacting with the benchmark by\n",
      "executing the actions suggested by the AssistantAgent and returning feedback.\n",
      "To assess the performance of the developed working system, we compare it with RCI (Kim\n",
      "et al., 2023), a recent solution for the MiniWoB++ benchmark that employs a set of self-\n",
      "critiquing prompts and has achieved state-of-the-art performance. In our evaluation, we\n",
      "use all available tasks in the official RCI code, with varying degrees of difficulty, to conduct\n",
      "a comprehensive analysis against MiniWobChat. Figure 18 illustrates that MiniWobChat\n",
      "achieves competitive performance in this evaluation4. Specifically, among the 49 available\n",
      "tasks, MiniWobChat achieves a success rate of 52.8%, which is only 3.6% lower than RCI,\n",
      "\n",
      "4We report the results of RCI by running its official code with default settings.\n",
      "\n",
      "35\n",
      "\n",
      "ExecutorReward & StateAction DecisionAssistantEnvironment State: HTML code for current web pagesReward: Success/Fail/OngoingAction decision: Next action to perform on a web pageAction decision=“Click the button with xpath’//button[id = ‘subbtn’]’“Environment State = “<div id=\"wrap\" data-wob_ref=\"2\" data-wob_eps=\"e0\"><div id=\"query\">Click button ONE, then click button TWO.</div><div id=\"area\" data-wob_ref=\"3\" data-wob_eps=\"e0\"><button id=\"subbtn\" style=\"position:absolute; left:50px; top:74px\" data-wob_ref=\"4\" data-wob_eps=\"e0\">ONE</button><button id=\"subbtn2\" style=\"position:absolute; left:98px; top:167px\" data-wob_ref=\"5\" data-wob_eps=\"e0\">TWO</button></div></div>“Reward = ”0” (Ongoing)\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "a method specifically designed for the MiniWob++ benchmark. It is worth noting that in\n",
      "most tasks, the difference between the two methods is mirrored as shown in Figure 18. If\n",
      "we consider 0.1 as a success rate tolerance for each task, i.e., two methods that differ within\n",
      "0.1 are considered to have the same performance, both methods outperform the other on\n",
      "the same number of tasks. For illustration purposes, we provide a case analysis in Table 6\n",
      "on four typical tasks.\n",
      "Additionally, we also explored the feasibility of using Auto-GPT for handling the same\n",
      "tasks. Auto-GPT faces challenges in handling tasks that involve complex rules due to its\n",
      "limited extensibility. It provides an interface for setting task goals using natural language.\n",
      "However, when dealing with the MiniWob++ benchmark, accurately instructing Auto-GPT\n",
      "to follow the instructions for using MiniWob++ proves challenging. There is no clear path\n",
      "to extend it in the manner of the two-agent chat facilitated by AutoGen.\n",
      "\n",
      "Takeaways: For this application, AutoGen stood out as a more user-friendly option, offering\n",
      "modularity and programmability: It streamlined the process with autonomous conversa-\n",
      "tions between the assistant and executor, and provided readily available solutions for\n",
      "agent-environment interactions. The built-in AssistantAgent was directly reusable and\n",
      "exhibited strong performance without customization. Moreover, the decoupling of the\n",
      "execution and assistant agent ensures that modifications to one component do not adversely\n",
      "impact the other. This convenience simplifies maintenance and future updates.\n",
      "\n",
      "Figure 18: Comparisons between RCI (state-of-the-art prior work) and MiniWobChat on\n",
      "the MiniWob++ benchmark. We utilize all available tasks in the official RCI code, each with\n",
      "varying degrees of difficulty, to conduct comprehensive comparisons. For each task, the\n",
      "success rate across ten different instances is reported. The results reveal that MiniWobChat\n",
      "attains a performance comparable to that of RCI. When a success rate tolerance of 0.1 is\n",
      "considered for each task, both methods outperform each other on an equal number of tasks.\n",
      "\n",
      "36\n",
      "\n",
      "choose-listclick-button-sequenceclick-buttonclick-checkboxes-largeclick-checkboxes-softclick-checkboxes-transferclick-checkboxesclick-collapsible-2click-collapsibleclick-colorclick-dialog-2click-dialogclick-linkclick-menuclick-optionclick-scroll-listclick-shadesclick-shapeclick-tab-2-hardclick-tab-2click-tabclick-test-2click-testclick-widgetcount-shapeemail-inbox-forward-nl-turkemail-inbox-forward-nlemail-inbox-nl-turkemail-inboxenter-dateenter-passwordenter-text-dynamicenter-textenter-timefocus-text-2focus-textgrid-coordinatelogin-user-popuplogin-usernavigate-treesearch-enginesimple-algebrasocial-media-allsocial-media-somesocial-mediaterminaluse-spinner0.00.51.0success rateRCIMiniWobChat\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 6: Cases analysis on four typical tasks from MiniWob++.\n",
      "\n",
      "click-dialog\n",
      "\n",
      "click-checkboxes-large\n",
      "\n",
      "count-shape\n",
      "\n",
      "use-spinner\n",
      "\n",
      "Correctness\n",
      "\n",
      "AutoGen: 10/10\n",
      "\n",
      "RCI: 10/10\n",
      "\n",
      "AutoGen: 5/10\n",
      "\n",
      "RCI: 0/10\n",
      "\n",
      "AutoGen: 2/10\n",
      "\n",
      "RCI: 0/10\n",
      "\n",
      "AutoGen: 0/10\n",
      "\n",
      "RCI: 1/10\n",
      "\n",
      "Main failure reason\n",
      "\n",
      "N/A.\n",
      "N/A.\n",
      "\n",
      "characters.\n",
      "\n",
      "AssistantAgent provides actions with infeasible\n",
      "\n",
      "RCI performs actions that are out of its plan.\n",
      "\n",
      "AssistantAgent provide actions with redundant\n",
      "\n",
      "content that can not convert to actions in the\n",
      "\n",
      "benchmark.\n",
      "\n",
      "RCI provides a wrong plan in most cases.\n",
      "\n",
      "AssistantAgent return actions out of its plan.\n",
      "\n",
      "RCI provides a wrong plan in most cases.\n",
      "\n",
      "F Example outputs from applications\n",
      "\n",
      "In this section, we include example outputs from the following applications and systems:\n",
      "\n",
      "• Application A1: autonomous solving process of one problem with: ChatGPT + Plugin\n",
      "(Table 7), AutoGen (Table 8), LangChain ReAct (Table 9), AutoGPT (Table 10), Multi-Agent\n",
      "Debate (Table 11), and ChatGPT + Code Interpreter (Table 13).\n",
      "\n",
      "• Application A4: an OptiGuide problem with AutoGen (Table 14) and ChatGPT + Code\n",
      "\n",
      "Interpreter (Table 12).\n",
      "\n",
      "• Application A1: preliminary evaluation on several alternative multi-agent systems:\n",
      "\n",
      "BabyAGI (Table 15), CAMEL (Table 16), and MetaGPT (Table 17).\n",
      "\n",
      "Table 7: Application A1, Scenario 1: Autonomous math problem-solving. ChatGPT+ Plugin\n",
      "(Wolfram Alpha) on the first qualitative example. The response from Wolfram contains the\n",
      "correct answer, but ChatGPT selected the wrong one.\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "Action ChatGPT + Plugin\n",
      "Input\n",
      "\n",
      "Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "REQUEST TO WOLFRAM:\n",
      "\n",
      "1 {\n",
      "2\n",
      "3\n",
      "4 }\n",
      "\n",
      "” input ” : ” s i m p l i f y ( s q r t ( 1 6 0 ) / s q r t ( 2 5 2 ) ) *\n",
      "( s q r t ( 2 4 5 ) / s q r t ( 1 0 8 ) ) ”\n",
      "\n",
      "RESPONSE FROM WOLFRAM\n",
      "\n",
      "i n t e r p r e t a t i o n :\n",
      "\n",
      "s q r t ( 1 6 0 ) / s q r t ( 2 5 2 ) x s q r t ( 2 4 5 ) / s q r t ( 1 0 8 )\n",
      "\n",
      "1 Query :\n",
      "2 ” s i m p l i f y ( s q r t ( 1 6 0 ) / s q r t ( 2 5 2 ) ) * ( s q r t ( 2 4 5 ) / s q r t ( 1 0 8 ) ) ”\n",
      "3 Input\n",
      "4 s i m p l i f y |\n",
      "5 R e s u l t s :\n",
      "6 (5 s q r t ( 4 2 ) ) /27\n",
      "7 (5 s q r t (14/3) ) /9\n",
      "8 Decimal approximation :\n",
      "9 1.2001371663718259686974013770533327143898526494552...\n",
      "10 Wolfram| Alpha website r e s u l t\n",
      "11 ( s q r t ( 1 6 0 ) / s q r t ( 2 5 2 ) ) * ( s q r t ( 2 4 5 ) / s q r t ( 1 0 8 ) ) ” :\n",
      "12 [ l i n k ]\n",
      "\n",
      "f o r ” s i m p l i f y\n",
      "\n",
      "The completely simplified and rationalized form of the given expression is:\n",
      "\n",
      "√\n",
      "\n",
      "5\n",
      "\n",
      "14/3\n",
      "9\n",
      "\n",
      "In decimal form, this is approximately 1.200137166371825968697401377053332714...\n",
      "\n",
      "37\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 8: Application A1, Scenario 1: Autonomous math problem-solving. AutoGen on the\n",
      "first qualitative example. AutoGen solves the problem correctly.\n",
      "\n",
      "Action\n",
      "Init chat\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "AutoGen\n",
      "Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "We can simplify and rationalize this denominator using Python’s symbolic\n",
      "mathematics library ‘sympy‘. Here is the Python code to resolve this:\n",
      "\n",
      "1 from sympy import sqrt , Rational\n",
      "2\n",
      "3 # Define the e n t i r e f r a c t i o n as a r a t i o n a l number\n",
      "4 f r a c t i o n = ( s q r t ( 1 6 0 ) / s q r t ( 2 5 2 ) ) * ( s q r t ( 2 4 5 ) / s q r t ( 1 0 8 ) )\n",
      "5\n",
      "6 # Simplify the f r a c t i o n\n",
      "7 s i m p l i f i e d = f r a c t i o n . s i m p l i f y ( )\n",
      "8\n",
      "9 # P r i n t\n",
      "10 p r i n t ( s i m p l i f i e d )\n",
      "\n",
      "the s i m p l i f i e d f r a c t i o n\n",
      "\n",
      "This code performs the requested simplification by constructing the fraction\n",
      "using the ‘Rational()‘ function from the ‘sympy‘ module, which automatically\n",
      "simplifies fractions when possible. The ‘sqrt()‘ function from the ‘sympy‘ module\n",
      "enables square root calculations. Finally, the ‘simplify()‘ function simplifies\n",
      "expressions when possible.\n",
      "exitcode: 0 (execution succeeded) Code output: 5*sqrt(42)/27\n",
      "TERMINATE\n",
      "\n",
      "g Auto Reply\n",
      "(cid:240)\n",
      "\n",
      "Table 9: Application A1, Scenario 1: Autonomous math problem-solving. LangChain ReAct\n",
      "on the first qualitative example. The generated code does not match the devised plan. The\n",
      "code returns a decimal number.\n",
      "\n",
      "Action\n",
      "Input\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "LangChain ReAct\n",
      "Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "Entering new AgentExecutor chain...\n",
      "To simplify this expression, I will first simplify each square root individually, then\n",
      "multiply the fractions as normal. The result should be a rational number. Action:\n",
      "Python REPL Action Input:\n",
      "\n",
      "1 import math\n",
      "2\n",
      "3 # C a l c u l a t e square r o o t s\n",
      "4 s q r t 1 6 0 = math . s q r t ( 1 6 0 )\n",
      "5 s q r t 2 5 2 = math . s q r t ( 2 5 2 )\n",
      "6 s q r t 2 4 5 = math . s q r t ( 2 4 5 )\n",
      "7 s q r t 1 0 8 = math . s q r t ( 1 0 8 )\n",
      "8\n",
      "9 # Multiply f r a c t i o n s\n",
      "10 numerator = s q r t 1 6 0 * s q r t 2 4 5\n",
      "11 denominator = s q r t 2 5 2 * s q r t 1 0 8\n",
      "12 r e s u l t = numerator / denominator\n",
      "13\n",
      "14 p r i n t ( r e s u l t )\n",
      "\n",
      "Observation: 1.200137166371826\n",
      "Thought: I now know the final answer Final Answer: The simplified and rationalized\n",
      "form of the expression is approximately 1.200137166371826.\n",
      "Finished chain.\n",
      "\n",
      "38\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 10: Application A1, Scenario 1: Autonomous math problem-solving. AutoGPT on the\n",
      "first qualitative example. We abort as the code never prints the result, and the system does\n",
      "not rectify it after 2 turns. AutoGPT is much more verbose compared to other frameworks.\n",
      "We have shortened some unnecessary content.\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "Action\n",
      "\n",
      "System\n",
      "\n",
      "Human\n",
      "\n",
      "System\n",
      "\n",
      "System\n",
      "\n",
      "AutoGPT\n",
      "\n",
      "Welcome back! Would you like me to return to being MathSolverGPT? Asking user via keyboard... Continue with the last settings?\n",
      "Name: MathSolverGPT\n",
      "Role: an intelligent math-solving AI that assists students, professionals,...\n",
      "Goals: [’Provide step-by-step solutions to math problems, ensuring clarity and understanding for the user...\n",
      "Continue (y/n):\n",
      "\n",
      "y\n",
      "\n",
      "MathSolverGPT has been created with the following details: Name: MathSolverGPT\n",
      "Role: an intelligent math-solving AI that assists students, professionals, and enthusiasts in solving a wide range of math problems,\n",
      "from basic arithmetic to advanced calculus and beyond.\n",
      "Goals: - Provide step-by-step solutions to math problems, ensuring clarity and understanding for the user. - Offer explanations\n",
      "and insights into the underlying concepts and principles behind the solutions, fostering a deeper understanding of mathematics. -\n",
      "Handle a variety of math problem types, including algebra, geometry, trigonometry, calculus, and more. ...\n",
      "\n",
      "MATHSOLVERGPT THOUGHTS: Without a specific task or question, it’s difficult to determine exactly one command to use. The\n",
      "user hasn’t provided any context or problem to solve.\n",
      "REASONING: The user’s request is too vague. They haven’t specified what they want me to do or what problem they want me to\n",
      "solve.\n",
      "PLAN: - Ask the user for more information or a specific task.\n",
      "CRITICISM: I should have asked the user for more information or a specific task in the first place.\n",
      "SPEAK: Could you please provide more information or specify a task?\n",
      "NEXT ACTION: COMMAND = ARGUMENTS = {}\n",
      "Enter ‘y’ to authorise command, ‘y -N’ to run N continuous commands, ‘n’ to exit program, or enter feedback for MathSolverGPT...\n",
      "Asking user via keyboard...\n",
      "\n",
      "g\n",
      "\n",
      "Human\n",
      "\n",
      "Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "MATHSOLVERGPT THOUGHTS: To solve this problem, I need to simplify and rationalize the denominator of the given expression.\n",
      "This involves simplifying the square roots and then multiplying the fractions. I can use Python’s math library to calculate the\n",
      "square roots and perform the multiplication.\n",
      "REASONING: The problem involves simplifying square roots and multiplying fractions. Python’s math library provides functions\n",
      "for these operations.\n",
      "PLAN: - Write a Python script to calculate the square roots and multiply the fractions. - Execute the script to get the simplified\n",
      "expression. CRITICISM: I need to ensure that I correctly calculate the square roots and perform the multiplication. I should also\n",
      "make sure to rationalize the denominator, as the problem specifies.\n",
      "SPEAK: Let’s simplify and rationalize the denominator of the given expression.\n",
      "NEXT ACTION: COMMAND = execute python code ARGUMENTS =\n",
      "\n",
      "1 { ' code ' :\n",
      "\n",
      "' import math\\n\\n# C a l c u l a t e the square r o o t s\\n s q r t 1 6 0 = math . s q r t ( 1 6 0 )\\n s q r t 2 5 2 =\n",
      "math . s q r t ( 2 5 2 )\\n s q r t 2 4 5 = math . s q r t ( 2 4 5 )\\n s q r t 1 0 8 = math . s q r t ( 1 0 8 )\\n\\n# Multiply the\n",
      "f r a c t i o n s\\n r e s u l t = ( s q r t 1 6 0 / s q r t 2 5 2 )\n",
      "r e s u l t\\ n s i m p l i f i e d r e s u l t = math . s i m p l i f y ( r e s u l t )\\n\\ n s i m p l i f i e d r e s u l t ' ,\n",
      "s i m p l i f y e x p r e s s i o n '}\n",
      "\n",
      "( s q r t 2 4 5 / s q r t 1 0 8 )\\n\\n# Simplify the\n",
      "'\n",
      "\n",
      "' name ' :\n",
      "\n",
      "*\n",
      "\n",
      "y\n",
      "\n",
      "-=-=-=-=-=-=-= COMMAND AUTHORISED BY USER -=-=-=-=-=-=-=\n",
      "Executing python file ’/app/autogpt/workspa...\n",
      "SYSTEM: Command execute python code returned: Error: Traceback (most recent call last): File “...”, line 13, in ¡module¿\n",
      "simplified result = math.simplify(result) AttributeError: module ’math’ has no attribute ’simplify’\n",
      "\n",
      "MATHSOLVERGPT THOUGHTS: The error message indicates that the ‘math’ module in Python does not have a ‘simplify’ function.\n",
      "I need to use the ‘sympy’ library instead, which provides a function for simplifying expressions.\n",
      "REASONING: The ‘math’ module in Python does not provide a function for simplifying expressions. The ‘sympy’ library, on the\n",
      "other hand, does provide such a function.\n",
      "PLAN: - Rewrite the Python script to use the ‘sympy’ library instead of the ‘math’ module. - Execute the script to get the simplified\n",
      "expression. CRITICISM: I should have known that the ‘math’ module does not provide a function for simplifying expressions. I\n",
      "should have used the ‘sympy’ library from the start. SPEAK: Let’s try again using the ‘sympy’ library to simplify the expression.\n",
      "NEXT ACTION: COMMAND = execute python code ARGUMENTS =\n",
      "\n",
      "1 { ' code ' :\n",
      "\n",
      "' import sympy as sp\\n\\n# C a l c u l a t e the square r o o t s\\n s q r t 1 6 0 = sp . s q r t ( 1 6 0 )\\\n",
      "\n",
      "n s q r t 2 5 2 = sp . s q r t ( 2 5 2 )\\n s q r t 2 4 5 = sp . s q r t ( 2 4 5 )\\n s q r t 1 0 8 = sp . s q r t ( 1 0 8 )\\n\\n# Multiply\n",
      "the f r a c t i o n s\\n r e s u l t = ( s q r t 1 6 0 / s q r t 2 5 2 )\n",
      "( s q r t 2 4 5 / s q r t 1 0 8 )\\n\\n# Simplify the\n",
      "r e s u l t\\ n s i m p l i f i e d r e s u l t = sp . s i m p l i f y ( r e s u l t )\\n\\ n s i m p l i f i e d r e s u l t ' ,\n",
      "s i m p l i f y e x p r e s s i o n '}\n",
      "\n",
      "' name ' :\n",
      "\n",
      "*\n",
      "\n",
      "'\n",
      "\n",
      "y\n",
      "\n",
      "SYSTEM: Command execute python code returned:\n",
      "\n",
      "MATHSOLVERGPT THOUGHTS: The command execution didn’t return any output, which is unusual. It seems there might be an\n",
      "issue with the execution of the Python code. I need to debug this.\n",
      "REASONING: The Python code execution should have returned a result. The absence of a result suggests that there might be an\n",
      "issue with the code or its execution.\n",
      "PLAN: - Review the Python code to identify any potential issues. - If necessary, modify the code and execute it again. CRITICISM: I\n",
      "should have ensured that the Python code was correct and would produce a result before executing it. SPEAK: It seems there was\n",
      "an issue with the execution of the Python code. Let’s try again.\n",
      "NEXT ACTION: COMMAND = execute python code ARGUMENTS = ... (Exact same code as last)\n",
      "\n",
      "SYSTEM: Command execute python code returned:\n",
      "\n",
      "39\n",
      "\n",
      "MATHSOLVERGPT THOUGHTS: The Python code execution still isn’t returning any output. It’s possible that the issue lies with\n",
      "the calculation of the square roots ...\n",
      "\n",
      "Human\n",
      "\n",
      "System\n",
      "\n",
      "Human\n",
      "\n",
      "System\n",
      "\n",
      "System\n",
      "\n",
      "Human\n",
      "\n",
      "control + C (Aborted)\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 11: Application A1, Scenario 1: Autonomous math problem-solving. Multi-Agent\n",
      "Debate on the first qualitative problem. It gives a wrong final answer.\n",
      "\n",
      "Action\n",
      "\n",
      "AutoGen\n",
      "\n",
      "g\n",
      "\n",
      "Topic\n",
      "\n",
      "Completely simplify and rationalize the denominator:\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "×\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "===== Debate Round-1 =====\n",
      "—– Affirmative side —–\n",
      "Ok, let’s simplify each square root separately. We want to find the simplest square root that can divide 160, 252, 245, and\n",
      "√\n",
      "108.\n",
      "√\n",
      "160: 160 can be decomposed as 16*10, where 16 is a perfect square, so\n",
      "1.\n",
      "√\n",
      "252 : 252 can be decomposed as 36*7, where 36 is a perfect square, so\n",
      "2.\n",
      "√\n",
      "245 =\n",
      "3.\n",
      "4.\n",
      "108 =\n",
      "108 : 108 can be decomposed as 36*3, where 36 is a perfect square, so\n",
      "Then we substitute the simplified square roots back into the expression, we have:\n",
      "\n",
      "√\n",
      "16 ∗ 10 =\n",
      "√\n",
      "36 ∗ 7 = 6\n",
      "36 ∗ 3 = 6\n",
      "\n",
      "49 ∗ 5, where 49 is a perfect square, so\n",
      "\n",
      "245 = 7 ∗ √\n",
      "\n",
      "16 ∗ √\n",
      "\n",
      "160 =\n",
      "252 =\n",
      "\n",
      "10 = 4\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "10\n",
      "\n",
      "7\n",
      "\n",
      "5\n",
      "\n",
      "3\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "√\n",
      "10\n",
      "7\n",
      "\n",
      "4\n",
      "6\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "× 7\n",
      "6\n",
      "\n",
      "4 ∗ 7\n",
      "6 ∗ 6\n",
      "\n",
      "·\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "(cid:114) 10 ∗ 5\n",
      "\n",
      "7 ∗ 3\n",
      "\n",
      "(cid:114) 50\n",
      "\n",
      "21\n",
      "\n",
      "=\n",
      "\n",
      "·\n",
      "\n",
      "7\n",
      "9\n",
      "\n",
      "√\n",
      "\n",
      "We are almost done, but we still need to rationalize the square root part of expression. Let’s multiply the square root part\n",
      "by\n",
      "\n",
      "21 at both the top and bottom to get rid of the square root at the denominator:\n",
      "\n",
      "Then this is the final answer! The expression\n",
      "\n",
      "·\n",
      "\n",
      "7\n",
      "9\n",
      "\n",
      "(cid:114) 50 ∗ 21\n",
      "\n",
      "21 ∗ 21\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "\n",
      "7\n",
      "\n",
      "=\n",
      "\n",
      "1050\n",
      "189\n",
      "\n",
      ".\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      ".\n",
      "\n",
      "× 7\n",
      "6\n",
      "\n",
      "=\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "√\n",
      "√\n",
      "\n",
      "28\n",
      "36\n",
      "\n",
      "50\n",
      "21\n",
      "\n",
      "4\n",
      "6\n",
      "\n",
      "√\n",
      "√\n",
      "10\n",
      "7\n",
      "√\n",
      "√\n",
      "\n",
      "7\n",
      "9\n",
      "\n",
      "50\n",
      "21\n",
      "\n",
      ".\n",
      "\n",
      "=\n",
      "\n",
      "×\n",
      "\n",
      "=\n",
      "\n",
      "√\n",
      "1050\n",
      "189\n",
      "\n",
      ".\n",
      "\n",
      "can be simplified to 7\n",
      "—– Negative side —–\n",
      "I do disagree with your final answer, but I think we mostly agree on the steps. Your simplifications of the square roots\n",
      "are correct, but you made a mistake in the final simplification part. Let me explain how I would complete the problem:\n",
      "As stated,\n",
      "\n",
      "This should then simplify to:\n",
      "\n",
      "You made a mistake in your calculation because you considered square root of 50/21, and you should have considered\n",
      "the simplified square root of 50 over the simplified square root of 21. The rationalization would become:\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "=\n",
      "\n",
      "7\n",
      "9\n",
      "\n",
      "·\n",
      "\n",
      "50\n",
      "21\n",
      "\n",
      "√\n",
      "21√\n",
      "21\n",
      "\n",
      "√\n",
      "\n",
      "7\n",
      "\n",
      "=\n",
      "\n",
      "1050\n",
      "189\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "√\n",
      "1050\n",
      "189\n",
      "\n",
      "This seems to coincide with your final answer, but it’s in fact a very different number, So, the original expression\n",
      "simplifies to 7\n",
      "Let’s now see if we disagree on this final answer.\n",
      "—– Moderator —–\n",
      "“Whether there is a preference”: “Yes”, “Supported Side”: “Negative”, “Reason”: “Both sides of the debate came to\n",
      "the same final answer. However, the negative side correctly identified a mistake in the affirmative side’s calculation,\n",
      "pointing out that the simplification should have been the square root of 50 over the square root of 21, not 50 over 21. The\n",
      "negative side shows a better understanding of the simplification process.”, “debate answer”: “ 7\n",
      "===== Debate Done! =====\n",
      "—– Base Answer —–\n",
      "Ok, let’s simplify each square root separately. We want to find the simplest square root that can divide 160, 252, 245, and\n",
      "√\n",
      "108.\n",
      "√\n",
      "160: 160 can be decomposed as 16*10, where 16 is a perfect square, so\n",
      "1.\n",
      "√\n",
      "252 : 252 can be decomposed as 36*7, where 36 is a perfect square, so\n",
      "2.\n",
      "√\n",
      "245 =\n",
      "3.\n",
      "4.\n",
      "108 : 108 can be decomposed as 36*3, where 36 is a perfect square, so\n",
      "108 =\n",
      "Then we substitute the simplified square roots back into the expression, we have:\n",
      "\n",
      "√\n",
      "16 ∗ 10 =\n",
      "√\n",
      "36 ∗ 7 = 6\n",
      "36 ∗ 3 = 6\n",
      "\n",
      "49 ∗ 5, where 49 is a perfect square, so\n",
      "\n",
      "245 = 7 ∗ √\n",
      "\n",
      "√\n",
      "1050\n",
      "189 ”\n",
      "\n",
      "16 ∗ √\n",
      "\n",
      "160 =\n",
      "252 =\n",
      "\n",
      "10 = 4\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "10\n",
      "\n",
      "7\n",
      "\n",
      "5\n",
      "\n",
      "3\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "√\n",
      "10\n",
      "7\n",
      "\n",
      "4\n",
      "6\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "× 7\n",
      "6\n",
      "\n",
      "4 ∗ 7\n",
      "6 ∗ 6\n",
      "\n",
      "·\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "(cid:114) 10 ∗ 5\n",
      "\n",
      "7 ∗ 3\n",
      "\n",
      "(cid:114) 50\n",
      "\n",
      "21\n",
      "\n",
      "=\n",
      "\n",
      "·\n",
      "\n",
      "7\n",
      "9\n",
      "\n",
      "√\n",
      "\n",
      "We are almost done, but we still need to rationalize the square root part of expression. Let’s multiply the square root part\n",
      "by\n",
      "\n",
      "21 at both the top and bottom to get rid of the square root at the denominator:\n",
      "\n",
      "·\n",
      "\n",
      "7\n",
      "9\n",
      "\n",
      "Then this is the final answer! The expression\n",
      "\n",
      "can be simplified to 7\n",
      "—– Debate Answer —–\n",
      "\n",
      "√\n",
      "1050\n",
      "189\n",
      "\n",
      ".\n",
      "\n",
      "(cid:114) 50 ∗ 21\n",
      "\n",
      "21 ∗ 21\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "\n",
      "7\n",
      "\n",
      "=\n",
      "\n",
      "1050\n",
      "189\n",
      "\n",
      ".\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "7\n",
      "\n",
      "√\n",
      "\n",
      "1050\n",
      "189\n",
      "\n",
      "—– Debate Reason —–\n",
      "Both sides of the debate came to the same final answer. However, the negative side correctly identified a mistake in the\n",
      "affirmative side’s calculation, pointing out that the simplification should have been the square root of 50 over the square\n",
      "root of 21, not 50 over 21. The negative side shows a better understanding of the simplification process.\n",
      "\n",
      "40\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 12: Application A3. ChatGPT+ Code Interpreter for OptiGuide. A sample question\n",
      "“What if the roasting cost is increased by 5% because of the potential salary increase?” is\n",
      "asked.\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "Action\n",
      "\n",
      "ChatGPT+ Code Interpreter\n",
      "\n",
      "Prompt Writer\n",
      "\n",
      "Customer open Web browser.\n",
      "For the source code “coffee.py”,\n",
      "Can you tell me:\n",
      "What if the roasting cost is increased by 5% because of the potential salary increase?\n",
      "\n",
      "Sure! Let’s first take a look at the contents of the “coffee.py” file to understand the code and how the roasting cost is calculated.\n",
      "This will allow us to determine the effect of a 5% increase in the roasting cost.\n",
      "...several lines omitted\n",
      "Would you like me to modify the code to reflect the 5% increase in roasting costs and run the modified code to observe the impact?\n",
      "If the code requires any specific input or parameters, please let me know!\n",
      "\n",
      "Prompt Writer\n",
      "\n",
      "Yes\n",
      "\n",
      "Great! Before proceeding, I’ll need to ensure that the Gurobi solver is not being used in this code, as my current environment\n",
      "does not have access to Gurobi. If the code does indeed use Gurobi, we can still analyze the effect of the change in roasting\n",
      "costs by understanding the structure of the code.\n",
      "...several lines omitted\n",
      "Alternatively, if you have access to a Gurobi license, you can make the necessary changes in the code and run it\n",
      "on your local machine.\n",
      "I can guide you through the process of making the necessary modifications to the code.\n",
      "Would you like me to proceed with the code analysis and explanation, or would you like guidance on making the changes yourself?\n",
      "\n",
      "Prompt Writer\n",
      "\n",
      "You can give me the full code, and I can run the code locally myself.\n",
      "\n",
      "Certainly! I’ll modify the code to reflect a 5% increase in both the light and dark roasting costs, and then provide the full\n",
      "code for you to run locally.\n",
      "...\n",
      "Download Modified Coffee.py\n",
      "If you have any questions or need further assistance, please feel free to ask!\n",
      "\n",
      "Prompt Safeguard\n",
      "\n",
      "Hi GPT, can you safecheck the generated code for me?\n",
      "Upload the generated code.\n",
      "\n",
      "DANGER\n",
      "\n",
      "Prompt Writer\n",
      "\n",
      "I have tried to run your code. However, the code triggered our safeguard, and it is not safe to run. Try again. Hint: don’t\n",
      "change roasting cost light or roasting cost light variables.\n",
      "\n",
      "I apologize for the oversight. It appears I made direct changes to the variables that could have led to issues with the code. Let’s\n",
      "take a different approach by analyzing the code to identify the appropriate place to apply the 5% increase in roasting costs.\n",
      "...\n",
      "Download Modified Safe Coffee.py\n",
      "...\n",
      "\n",
      "Prompt Safeguard\n",
      "\n",
      "Hi GPT, can you safecheck the generated code for me one more time?\n",
      "Upload the generated code.\n",
      "\n",
      "DANGER\n",
      "\n",
      "Prompt Writer\n",
      "\n",
      "I have tried to run your code again. However, the code triggered our safeguard, and it is not safe to run. Try again. Hint:\n",
      "don’t change roasting cost light or roasting cost light variables.\n",
      "\n",
      "I apologize for the continued confusion.\n",
      "...\n",
      "Download Final Modified Safe Coffee.py\n",
      "...\n",
      "\n",
      "Prompt Safeguard\n",
      "\n",
      "Hi GPT, can you safecheck the generated code for me one more time?\n",
      "Upload the generated code.\n",
      "\n",
      "SAFE\n",
      "\n",
      "Run Code\n",
      "\n",
      "Obtain the terminal results:\n",
      "Optimizer version 9.5.1 build v9.5.1rc2 (linux64)\n",
      "Thread count: 64 physical cores, 128 logical processors, using up to 32\n",
      "threads\n",
      "[63 lines of output ignored]\n",
      "Optimal cost: 2526.5\n",
      "\n",
      "Prompt Writer\n",
      "\n",
      "Here is the execution result. [Copy + Paste the terminal output here.] Can you extract the final answer to me? Remember to\n",
      "compare with the original cost of 2470.\n",
      "\n",
      "Certainly! The execution result you’ve provided indicates the optimal\n",
      "cost for the modified scenario, where the roasting costs were increased\n",
      "by 5%. Here’s the comparison:\n",
      "Original Cost: 2470\n",
      "Modified Cost (with 5% increase in roasting costs): 2526.5\n",
      "The increase in roasting costs has led to an increase in the overall cost\n",
      "by 56.5, reflecting the impact of the potential salary increase on the\n",
      "roasting cost.\n",
      "If you need any further insights or assistance, please let me know!\n",
      "\n",
      "41\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 13: Application A1. Scenario 1: autonomous math solving. ChatGPT+ Code Interpreter\n",
      "on the first qualitative example. The code generated does not match the devised plan. The\n",
      "code returns a decimal number.\n",
      "\n",
      "Action ChatGPT+ Code Interpreter\n",
      "Input\n",
      "\n",
      "Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "To simplify and rationalize the expression, we first simplify the radicals in the numerator\n",
      "and denominator by factoring out the largest perfect squares from the numbers under\n",
      "the square root.\n",
      "The perfect square factors of 160, 252, 245, and 108 are 16, 4, 1, and 36, respectively. Let’s\n",
      "factorize and simplify:\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "16 × 10\n",
      "√\n",
      "4 × 63\n",
      "\n",
      "×\n",
      "\n",
      "=\n",
      "\n",
      "√\n",
      "245√\n",
      "36 × 3\n",
      "√\n",
      "√\n",
      "ab =\n",
      "\n",
      "√\n",
      "\n",
      "a\n",
      "\n",
      "b and a\n",
      "\n",
      "b × c\n",
      "\n",
      "d = a×c\n",
      "b×d .\n",
      "\n",
      "We can simplify this further by applying the property\n",
      "Python\n",
      "\n",
      "1 import math\n",
      "2\n",
      "3 # factoring the square roots\n",
      "4 sqrt_160 = math . sqrt (16) * math . sqrt (10)\n",
      "5 sqrt_252 = math . sqrt (4) * math . sqrt (63)\n",
      "6 sqrt_245 = math . sqrt (245)\n",
      "7 sqrt_108 = math . sqrt (36) * math . sqrt (3)\n",
      "8\n",
      "9 # simplify the fraction\n",
      "10 numerator = sqrt_160 * sqrt_245\n",
      "11 denominator = sqrt_252 * sqrt_108\n",
      "12 simplified_fraction = numerator / denominator\n",
      "13\n",
      "14 simplified_fraction\n",
      "\n",
      "Result:\n",
      "\n",
      "1 1.200137166371826\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "The completely simplified and rationalized form of the given expression is approxi-\n",
      "mately 1.200.\n",
      "\n",
      "Table 14: Application A3. AutoGen with OptiGuide. The same question “What if the roasting\n",
      "cost is increased by 5% because of the potential salary increase?” is asked.\n",
      "\n",
      "Action\n",
      "\n",
      "AutoGen\n",
      "\n",
      "g Prompt What if the roasting cost is increased by 5% because of the potential salary increase?\n",
      "(cid:240)\n",
      "\n",
      "After increasing the roasting costs by 5%, I’ve re-calculated the optimal coffee\n",
      "distribution solution for the supply chain. As a result, the new optimal total cost\n",
      "has become 2526.5, compared to the initial cost of 2470.0. This indicates that the\n",
      "increased roasting costs have caused the overall distribution cost to rise by 56.5\n",
      "units.\n",
      "\n",
      "42\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 15: Application A1. Scenario 1: autonomous math solving. Preliminary test with\n",
      "BabyAGI.\n",
      "\n",
      "Action\n",
      "\n",
      "Set .env\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "BabyAGI\n",
      "\n",
      "OBJECTIVE=Solve math problems\n",
      "INITIAL TASK=Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "Solve math problems\n",
      "Initial task: Completely simplify and rationalize the denominator:\n",
      "√\n",
      "*****TASK LIST*****\n",
      "245√\n",
      "• Completely simplify and rationalize the denominator:\n",
      "108\n",
      "√\n",
      "*****NEXT TASK*****\n",
      "160√\n",
      "Completely simplify and rationalize the denominator:\n",
      "252\n",
      "*****TASK RESULT*****\n",
      "First, let’s simplify each square root separately:\n",
      "√\n",
      "-\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "×\n",
      "\n",
      "×\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "160 =\n",
      "√\n",
      "\n",
      "252 =\n",
      "√\n",
      "\n",
      "245 =\n",
      "\n",
      "16 ∗ 10 =\n",
      "√\n",
      "\n",
      "4 ∗ 63 =\n",
      "√\n",
      "\n",
      "49 ∗ 5 =\n",
      "\n",
      "16 ∗\n",
      "√\n",
      "\n",
      "4 ×\n",
      "√\n",
      "\n",
      "49 ×\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "36 ∗ 3 =\n",
      "\n",
      "108 =\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "10\n",
      "\n",
      "10 = 4 ∗\n",
      "√\n",
      "√\n",
      "\n",
      "63 = 2\n",
      "√\n",
      "\n",
      "63\n",
      "√\n",
      "\n",
      "5 = 7\n",
      "\n",
      "5\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "3\n",
      "\n",
      "3 = 6\n",
      "\n",
      "36 ×\n",
      "2 ∗ √\n",
      "10√\n",
      "63\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "× 7\n",
      "2\n",
      "\n",
      "4 ∗ √\n",
      "√\n",
      "\n",
      "2\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "10\n",
      "63\n",
      "\n",
      "× 7\n",
      "6\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "=\n",
      "\n",
      "Now, substitute these values into the original expression which gives:\n",
      "\n",
      "We get rid of the square root in the denominator by multiplying the fractions which gives:\n",
      "√\n",
      "2√\n",
      "20\n",
      "27\n",
      "\n",
      "√\n",
      "2 ∗ 7\n",
      "10 ∗ 5\n",
      "2 ∗ √\n",
      "63 ∗ 3\n",
      "\n",
      "√\n",
      "50√\n",
      "14\n",
      "189\n",
      "\n",
      "14 ∗ 5\n",
      "√\n",
      "27\n",
      "7\n",
      "\n",
      "2 ∗ 10√\n",
      "27\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "2\n",
      "\n",
      ".\n",
      "\n",
      "= 2\n",
      "√\n",
      "27√\n",
      "27\n",
      "\n",
      "6\n",
      "\n",
      "54\n",
      "\n",
      "∗\n",
      "\n",
      "= 20\n",
      "\n",
      "√\n",
      "27√\n",
      "27\n",
      "\n",
      "√\n",
      "6\n",
      "27 .\n",
      "\n",
      "√\n",
      "27 = 60\n",
      "\n",
      "√\n",
      "27 = 20∗3\n",
      "\n",
      "To simplify further and rationalize the denominator, we multiply by\n",
      "√\n",
      "2√\n",
      "= 20\n",
      "27\n",
      "Simplifying further gives:\n",
      "√\n",
      "= 20\n",
      "9\n",
      "*****TASK CREATION AGENT PROMPT****\n",
      "You are to use the result from an execution agent to create new tasks with the following objective: Solve math problems.\n",
      "The last completed task has the result: First, let’s simplify each square root separately:\n",
      "-\n",
      "\n",
      "which gives:\n",
      "\n",
      "6\n",
      "\n",
      ".\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "160 =\n",
      "\n",
      "16 ∗ 10 =\n",
      "\n",
      "16 ∗\n",
      "\n",
      "10 = 4 ∗\n",
      "\n",
      "√\n",
      "\n",
      "10\n",
      "\n",
      "...Repeat after “First, let’s simplify each square..”\n",
      "\n",
      "Now, substitute these values into the original expression which gives:\n",
      "\n",
      "4 ∗ √\n",
      "√\n",
      "\n",
      "2\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "10\n",
      "63\n",
      "\n",
      "× 7\n",
      "6\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "=\n",
      "\n",
      "2 ∗ √\n",
      "10√\n",
      "63\n",
      "\n",
      "√\n",
      "√\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "× 7\n",
      "2\n",
      "\n",
      "We get rid of the square root in the denominator by multiplying the fractions which gives:\n",
      "√\n",
      "2√\n",
      "20\n",
      "27\n",
      "\n",
      "√\n",
      "2 ∗ 7\n",
      "10 ∗ 5\n",
      "2 ∗ √\n",
      "63 ∗ 3\n",
      "\n",
      "√\n",
      "50√\n",
      "14\n",
      "189\n",
      "\n",
      "14 ∗ 5\n",
      "√\n",
      "27\n",
      "7\n",
      "\n",
      "2 ∗ 10√\n",
      "27\n",
      "\n",
      "√\n",
      "\n",
      "√\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "2\n",
      "\n",
      ".\n",
      "\n",
      "To simplify further and rationalize the denominator, we multiply by\n",
      "\n",
      "which gives:\n",
      "\n",
      "√\n",
      "2√\n",
      "20\n",
      "27\n",
      "\n",
      "∗\n",
      "\n",
      "√\n",
      "27√\n",
      "27\n",
      "\n",
      "=\n",
      "\n",
      "√\n",
      "\n",
      "27\n",
      "\n",
      "20\n",
      "\n",
      "54\n",
      "\n",
      "=\n",
      "\n",
      "=\n",
      "\n",
      "= 2\n",
      "√\n",
      "27√\n",
      "27\n",
      "√\n",
      "6\n",
      "\n",
      "20 ∗ 3\n",
      "27\n",
      "\n",
      "√\n",
      "\n",
      "=\n",
      "\n",
      "6\n",
      "\n",
      ".\n",
      "\n",
      "60\n",
      "\n",
      "27\n",
      "\n",
      "6\n",
      "\n",
      ". This result was based on this task description: Completely simplify and rationalize the denominator:\n",
      "\n",
      "Simplifying further gives:\n",
      "√\n",
      "= 20\n",
      "9\n",
      "√\n",
      "245√\n",
      ". Based on the result, return a list of tasks to be completed in order to meet the objective. Return one task per line in\n",
      "108\n",
      "your response. The result must be a numbered list in the format:\n",
      "# First task # Second task\n",
      "The number of each entry must be followed by a period. If your list is empty, write “There are no tasks to add at this\n",
      "time.” Unless your list is empty, do not include any headers before your numbered list or follow your numbered list\n",
      "with any other output.\n",
      "****TASK CREATION AGENT RESPONSE****\n",
      "1. Simplify and rationalize the denominator for the expression\n",
      "\n",
      "2. Simplify and rationalize the denominator\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "225√\n",
      "45\n",
      "\n",
      "√\n",
      "200√\n",
      "125\n",
      "\n",
      "...Until 10\n",
      "\n",
      "for the expression\n",
      "Adding new tasks to task storage ‘task name’: ‘Simplify and rationalize the denominator for the expression frac-\n",
      "sqrt225sqrt45timesfracsqrt200sqrt125’, ‘task id’: 2\n",
      "‘task name’: ‘Simplify and rationalize the denominator for the expression fracsqrt289sqrt361timesfracsqrt100sqrt72’,\n",
      "‘task id’: 3\n",
      "...Until task id 11\n",
      "****TASK PRIORITIZATION AGENT PROMPT****\n",
      "You are tasked with prioritizing the following tasks: Simplify and rationalize the denominator for the expres-\n",
      "sion fracsqrt225sqrt45timesfracsqrt200sqrt125 Simplify and rationalize the denominator for the expression frac-\n",
      "sqrt289sqrt361timesfracsqrt100sqrt72\n",
      "...Aborted\n",
      "\n",
      "√\n",
      "289√\n",
      "361\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "100√\n",
      "72\n",
      "\n",
      "43\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 16: Application A1, Scenario 1: Autonomous math problem-solving. Preliminary test\n",
      "with CAMEL. We constructed two roles: “Math Solver” and “Python Programmer”. The\n",
      "resulting code cannot be executed. The conversation continues, and the roles are not keen\n",
      "on solving the problem and giving an answer.\n",
      "\n",
      "Action\n",
      "\n",
      "CAMEL\n",
      "\n",
      "g\n",
      "\n",
      "Set task prompt\n",
      "\n",
      "Completely simplify and rationalize the denominator:\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "×\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "System\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "sys message*************\n",
      "\n",
      "AI\n",
      "\n",
      "SystemMessage(role name=‘Python\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "Programmer’,\n",
      "**************Assistant\n",
      "role type=<RoleType.ASSISTANT: ‘assistant’>, meta dict=‘task’:\n",
      "‘Using Python programming language, write\n",
      "a program that accepts four integers as input, applies square root function to each, simplifies and rationalizes the\n",
      "denominator of the fraction resulting from the multiplication of two fractions:\n",
      ", and returns the simplified\n",
      "expression.’, ‘assistant role’: ‘Python Programmer’, ‘user role’: ‘Math Solver’, role=‘system’, content=‘Never forget you\n",
      "are a Python Programmer and I am a Math Solver. Never flip roles! ...)\n",
      "**************AI User sys message*************\n",
      "SystemMessage(role name=‘Math Solver’, role type=<RoleType.USER: ‘user’>, meta dict=‘task’: ‘Using Python pro-\n",
      "gramming language, write a program that accepts four integers as input, applies square root function to each, simplifies\n",
      "and rationalizes the denominator of the fraction resulting from the multiplication of two fractions:\n",
      ", and\n",
      "returns the simplified expression.’, ‘assistant role’: ‘Python Programmer’, ‘user role’: ‘Math Solver’, role=‘system’,\n",
      "content=‘Never forget you are a Math Solver and I am a Python Programmer. Never flip roles! You will always instruct\n",
      "me.We share a common interest in collaborating to successfully complete a task.I must help you to complete the task.Here\n",
      "is the task: Using Python programming language, write a program that accepts four integers as input, applies square\n",
      "root function to each, simplifies and rationalizes the denominator of the fraction resulting from the multiplication of two\n",
      "fractions:\n",
      "**************Original task prompt*************\n",
      "Completely simplify and rationalize the denominator:\n",
      "**************Specified task prompt*************\n",
      "Using Python programming language, write a program that accepts four integers as input, applies square root function\n",
      "to each, simplifies and rationalizes the denominator of the fraction resulting from the multiplication of two fractions:\n",
      "√\n",
      "160√\n",
      "252\n",
      "**************Final task prompt*************\n",
      "Using Python programming language, write a program that accepts ...\n",
      "\n",
      ", and returns the simplified expression.. ...)\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      ", and returns the simplified expression.\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "×\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "g\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "AI User\n",
      "\n",
      "Instruction: Import the necessary libraries for the task. Input: None\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Solution: To solve this task, we will need the ‘math‘ library for the square root function and the ‘fractions‘ library to\n",
      "simplify the resulting fraction. Here is how to import these libraries:\n",
      "\n",
      "1 import math\n",
      "2 from fractions import Fraction\n",
      "\n",
      "The ‘math‘ library provides functions that deal with mathematical operations. The ‘sqrt‘ function, which we will use in\n",
      "this task, is part of this library.\n",
      "The ‘fractions‘ library provides functions for creating and manipulating rational numbers. The ‘Fraction‘ function, which\n",
      "we will use to simplify the resulting fraction, is part of this library.\n",
      "Next request.\n",
      "\n",
      "AI User\n",
      "\n",
      "Instruction: Define a function that accepts four integers as input. Input: None\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Solution: Let’s define a function named ‘simplify fraction‘ that accepts four integers as input. These integers will\n",
      "represent the numbers under the square root in the fractions.\n",
      "\n",
      "1 def simplify_fraction (a , b , c , d):\n",
      "2\n",
      "\n",
      "pass\n",
      "\n",
      "In this function, ‘a’, ‘b’, ‘c’, and ‘d’ are the parameters that will accept the four integers as input. The ‘pass’ statement is a\n",
      "placeholder and will be replaced with actual code in the next steps.\n",
      "Next request.\n",
      "\n",
      "AI User\n",
      "\n",
      "Instruction: Inside the function, apply the square root function to each of the input integers. Input: None\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Solution: We will use the ‘math.sqrt’ function from the ‘math’ library to apply the square root to each of the input\n",
      "integers. Here is how to do it:\n",
      "\n",
      "1 def simplify_fraction (a , b , c , d):\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "\n",
      "sqrt_a = math . sqrt (a)\n",
      "sqrt_b = math . sqrt (b)\n",
      "sqrt_c = math . sqrt (c)\n",
      "sqrt_d = math . sqrt (d)\n",
      "\n",
      "In this code, ‘sqrt a’, ‘sqrt b’, ‘sqrt c’, and ‘sqrt d’ are variables that store the square root of the input integers ‘a’, ‘b’, ‘c’,\n",
      "and ‘d’ respectively.\n",
      "Next request.\n",
      "\n",
      "g\n",
      "\n",
      "Human\n",
      "\n",
      "Abort\n",
      "\n",
      "44\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 17: Application A1, Scenario 1: Autonomous math problem-solving. Preliminary\n",
      "evaluation on MetaGPT. It does not solve the math problem but gives a product solution.\n",
      "\n",
      "Action MetaGPT\n",
      "\n",
      "g Prompt Completely simplify and rationalize the denominator:\n",
      "\n",
      "√\n",
      "160√\n",
      "252\n",
      "\n",
      "×\n",
      "\n",
      "√\n",
      "245√\n",
      "108\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "The boss has tasked me with creating a successful product that is efficient.\n",
      "## Product Goals\n",
      "\n",
      "1 [\n",
      "2\n",
      "\n",
      "3\n",
      "4\n",
      "5 ]\n",
      "\n",
      "`` Create a product that meets the needs of the target\n",
      "market \",\n",
      "`` Ensure the product is efficient and easy to use \",\n",
      "`` Achieve a high level of customer satisfaction \"\n",
      "\n",
      "## User Stories\n",
      "\n",
      "1 [\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7 ]\n",
      "\n",
      "``As a user , I want a product that is easy to\n",
      "navigate so that I can find what I need quickly \",\n",
      "``As a user , I want a product that is reliable and\n",
      "efficient so that I can depend on it \",\n",
      "``As a user , I want a product that meets my needs so\n",
      "that I can get value for my money \",\n",
      "``As a user , I want a product that is constantly\n",
      "updated and improved so that I can enjoy the best\n",
      "features \",\n",
      "``As a user , I want a product that offers good\n",
      "customer support so that I can get help when I need it\n",
      "\"\n",
      "\n",
      "## Competitive Analysis\n",
      "\n",
      "1 [\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9 ]\n",
      "\n",
      "`` Product A: Offers similar features but lacks\n",
      "efficiency \",\n",
      "`` Product B: Highly efficient but does not meet all\n",
      "the needs of the target market \",\n",
      "`` Product C: Has a high level of customer\n",
      "satisfaction but is not easy to navigate \",\n",
      "`` Product D: Is constantly updated and improved but\n",
      "lacks reliability \",\n",
      "`` Product E: Offers good customer support but is not\n",
      "efficient \",\n",
      "`` Product F: Is reliable and efficient but does not\n",
      "offer good customer support \",\n",
      "`` Our Target Product : Aims to combine all the best\n",
      "features of the competitors while improving on their\n",
      "weaknesses \"\n",
      "\n",
      "## Competitive Quadrant Chart\n",
      "\n",
      "g Human Abort\n",
      "\n",
      "45\n",
      "\n",
      "\fPublished as a conference paper at COLM 2024\n",
      "\n",
      "Table 18: Application A7. Example output of MiniWobChat on one web manipulation task\n",
      "“click-button-sequence.”\n",
      "\n",
      "Action\n",
      "\n",
      "AutoGen\n",
      "\n",
      "g\n",
      "\n",
      "Init chat\n",
      "\n",
      "Executor agent to AssistantAgent:\n",
      "We have an autonomous computer control agent that can perform atomic instructions specified by natural language to\n",
      "control computers. There are two types of instructions it can execute.\n",
      "First, given the instruction that matches the regular expression ``ˆtype\\s.{1,}$\", it can type a list of characters via the\n",
      "keyboard. This instruction should specify the target keyboard input for the agent to type. Before this typing instruction,\n",
      "you should first locate the cursor by clicking the input box with click instruction.\n",
      "Second, given the instruction that matches the regular expression, ``ˆclickxpath\\s.{1,}$\", it can click an HTML\n",
      "element with an xpath that is visible on the webpage. The target of this instruction should be a valid xpath. Below is the\n",
      "HTML code of the webpage where the agent should solve a task.\n",
      "\n",
      "1 <div id =”wrap” data −wob ref =”2” data −wob eps=”e0”>\n",
      "2 <div id =”query”>Click button ONE,\n",
      "3 <div id =” area ” data −wob ref =”3” data −wob eps=”e0”>\n",
      "4\n",
      "\n",
      "<button id =”subbtn ” s t y l e =” p o s i t i o n : absolute ;\n",
      "\n",
      "=”4” data −wob eps=”e0”>ONE</button>\n",
      "\n",
      "then c l i c k button TWO.</div>\n",
      "\n",
      "l e f t : 1 0 3 px ;\n",
      "\n",
      "top : 8 7 px” data −wob ref\n",
      "\n",
      "5\n",
      "\n",
      "<button id =”subbtn2 ” s t y l e =” p o s i t i o n : absolute ;\n",
      "\n",
      "l e f t : 4 4 px ;\n",
      "\n",
      "top : 9 7 px” data −wob ref\n",
      "\n",
      "=”5” data −wob eps=”e0”>TWO</button>\n",
      "\n",
      "6 </div>\n",
      "7 </div>\n",
      "\n",
      "task: Click button ONE, then click button TWO.\n",
      "plan:\n",
      "1. Click the button with xpath “//button[@id=‘subbtn’]”.\n",
      "2. Click the button with xpath “//button[@id=‘subbtn2’]”.\n",
      "Current task: Click button ONE, then click button TWO.\n",
      "plan:\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "***************************************************************\n",
      "AssistantAgent to Executor agent:\n",
      "1. Click the button with xpath “//button[@id=‘subbtn’]”.\n",
      "2. Click the button with xpath “//button[@id=‘subbtn2’]”.\n",
      "***************************************************************\n",
      "Executor agent to AssistantAgent:\n",
      "Below is the HTML code of the webpage where the agent should solve a task.\n",
      "\n",
      "1 <div id =”wrap” data −wob ref =”2” data −wob eps=”e0”>\n",
      "2 <div id =”query”>Click button ONE,\n",
      "3 <div id =” area ” data −wob ref =”3” data −wob eps=”e0”>\n",
      "4\n",
      "\n",
      "<button id =”subbtn ” s t y l e =” p o s i t i o n : absolute ;\n",
      "\n",
      "=”4” data −wob eps=”e0”>ONE</button>\n",
      "\n",
      "then c l i c k button TWO.</div>\n",
      "\n",
      "l e f t : 1 0 3 px ;\n",
      "\n",
      "top : 8 7 px” data −wob ref\n",
      "\n",
      "5\n",
      "\n",
      "<button id =”subbtn2 ” s t y l e =” p o s i t i o n : absolute ;\n",
      "\n",
      "l e f t : 4 4 px ;\n",
      "\n",
      "top : 9 7 px” data −wob ref\n",
      "\n",
      "=”5” data −wob eps=”e0”>TWO</button>\n",
      "\n",
      "6 </div>\n",
      "7 </div>\n",
      "\n",
      "Current task: Click button ONE, then click button TWO.\n",
      "Here is a plan you are following now.\n",
      "1. Click the button with xpath “//button[@id=‘subbtn’]”.\n",
      "2. Click the button with xpath “//button[@id=‘subbtn2’]”.\n",
      "We have a history of instructions that have been already executed by the autonomous agent so far.\n",
      "No instruction has been executed yet.\n",
      "Based on the plan and the history of instructions executed so far, the first instruction should be ‘\n",
      "***************************************************************\n",
      "AssistantAgent to Executor agent:\n",
      "clickxpath //button[@id=‘subbtn’]\n",
      "***************************************************************\n",
      "Executor agent to AssistantAgent:\n",
      "Hold on, please wait for my next instruction.\n",
      "***************************************************************\n",
      "AssistantAgent to Executor agent:\n",
      "Sure, I’ll be here when you’re ready with your next instruction.\n",
      "***************************************************************\n",
      "Executor agent to AssistantAgent:\n",
      "Below is the HTML code of the webpage where the agent should solve a task.\n",
      "\n",
      "1 <div id =”wrap” data −wob ref =”2” data −wob eps=”e0”>\n",
      "2 <div id =”query”>Click button ONE,\n",
      "3 <div id =” area ” data −wob ref =”3” data −wob eps=”e0”>\n",
      "4\n",
      "\n",
      "<button id =”subbtn ” s t y l e =” p o s i t i o n : absolute ;\n",
      "\n",
      "l e f t : 1 0 3 px ;\n",
      "=”4” data −wob eps=”e0 ” data −tampered=”e0”>ONE</button>\n",
      "l e f t : 4 4 px ;\n",
      "\n",
      "<button id =”subbtn2 ” s t y l e =” p o s i t i o n : absolute ;\n",
      "\n",
      "then c l i c k button TWO.</div>\n",
      "\n",
      "5\n",
      "\n",
      "=”5” data −wob eps=”e0”>TWO</button>\n",
      "\n",
      "top : 8 7 px” data −wob ref\n",
      "\n",
      "top : 9 7 px” data −wob ref\n",
      "\n",
      "6 </div>\n",
      "7 </div>\n",
      "\n",
      "Current task: Click button ONE, then click button TWO.\n",
      "Here is a plan you are following now.\n",
      "1. Click the button with xpath “//button[@id=‘subbtn’]”.\n",
      "2. Click the button with xpath “//button[@id=‘subbtn2’]”.\n",
      "We have a history of instructions that have been already executed by the autonomous agent so far.\n",
      "1: clickxpath //button[@id=‘subbtn’]\n",
      "Based on the plan and the history of instructions executed so far, the next proper instruction should be ‘\n",
      "***************************************************************\n",
      "AssistantAgent to Executor agent:\n",
      "clickxpath //button[@id=‘subbtn2’]\n",
      "***************************************************************\n",
      "Executor agent to AssistantAgent:\n",
      "SUCCESS!!!!\n",
      "\n",
      "(cid:240)\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "46\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "output_string = StringIO()\n",
    "with open(source, 'rb') as in_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "print(output_string.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ford_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
