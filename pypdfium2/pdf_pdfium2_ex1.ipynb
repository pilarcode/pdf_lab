{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pypdfium2\n",
    "\n",
    "https://pypi.org/project/pypdfium2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../AutoGen_LLM_agent.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdfium2 as pdfium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfium.PdfDocument(source)\n",
    "version = pdf.get_version()  # get the PDF standard version\n",
    "n_pages = len(pdf)  # get the number of pages in the document\n",
    "page = pdf[0]  # load a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PdfPage uuid:1f076b7f>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmap = page.render(\n",
    "    scale = 1,    # 72dpi resolution\n",
    "    rotation = 0, # no additional rotation\n",
    "    # ... further rendering options\n",
    ")\n",
    "pil_image = bitmap.to_pil()\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'via Multi-Agent Conversations\\r\\nQingyun Wu∗\\r\\nPenn State University\\r\\nqingyun@autogen.team\\r\\nGagan Bansal\\r\\nMicrosoft Research\\r\\ngaganbansal@microsoft.com\\r\\nJieyu Zhang\\r\\nUniversity of Washington\\r\\njieyuz2@cs.washington.edu\\r\\nYiran Wu\\r\\nPenn State University\\r\\nyiran.wu@psu.edu\\r\\nBeibin Li\\r\\nMicrosoft Research\\r\\nbeibin.li@microsoft.com\\r\\nErkang Zhu\\r\\nMicrosoft Research\\r\\nerkang.zhu@microsoft.com\\r\\nLi Jiang\\r\\nMicrosoft\\r\\nlijiang1@microsoft.com\\r\\nXiaoyun Zhang\\r\\nMicrosoft\\r\\nxiaoyun.zhang@microsoft.com\\r\\nShaokun Zhang\\r\\nPenn State University\\r\\nshaokun.zhang@psu.edu\\r\\nJiale Liu\\r\\nPenn State University\\r\\njjl7199@psu.edu\\r\\nAhmed Awadallah\\r\\nMicrosoft Research\\r\\nhassanam@microsoft.com\\r\\nRyen W. White\\r\\nMicrosoft Research\\r\\nryenw@microsoft.com\\r\\nDoug Burger\\r\\nMicrosoft Research\\r\\ndburger@microsoft.com\\r\\nChi Wang*\\r\\nMicrosoft Research\\r\\nchi@autogen.team\\r\\nAbstract\\r\\nWe present AutoGen,\\r\\n1 an open-source framework that allows developers to\\r\\nbuild LLM applications by composing multiple agents to converse with each\\r\\nother to accomplish tasks. AutoGen agents are customizable, conversable,\\r\\nand can operate in various modes that employ combinations of LLMs,\\r\\nhuman inputs, and tools. It also enables developers to create flexible agent\\r\\nbehaviors and conversation patterns for different applications using both\\r\\nnatural language and code. AutoGen serves as a generic infrastructure\\r\\nand is widely used by AI practitioners and researchers to build diverse\\r\\napplications of various complexities and LLM capacities. We demonstrate\\r\\nthe framework’s effectiveness with several pilot applications, on domains\\r\\nranging from mathematics and coding to question-answering, supply-chain\\r\\noptimization, online decision-making, and entertainment.\\r\\n1 Introduction\\r\\nLarge language models (LLMs) are becoming a crucial building block in developing power\\x02ful agents that utilize LLMs for reasoning, tool usage, and adapting to new observations (Yao\\r\\net al., 2022; Xi et al., 2023; Wang et al., 2023). As the scope and complexity of tasks suitable\\r\\nfor LLMs increase, a natural strategy for enhancing agent capabilities is to employ multiple\\r\\ncooperating agents. Prior work suggests that multiple agents can help encourage divergent\\r\\nthinking (Liang et al., 2023), improve factuality and reasoning (Du et al., 2023; Naik et al.,\\r\\n2023), and provide guardrails (Wu et al., 2023). Given the early promising evidence, an\\r\\nintriguing question is: How can we facilitate the development of LLM applications that span'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a text page helper\n",
    "textpage = page.get_textpage()\n",
    "\n",
    "width, height = page.get_size()\n",
    "# Extract text from the whole page\n",
    "text_all = textpage.get_text_range()\n",
    "# Extract text from a specific rectangular area\n",
    "text_part = textpage.get_text_bounded(left=50, bottom=100, right=width-50, top=height-100)\n",
    "text_part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Introduction -> 1  # 1 [108.0, 219.9149932861328, 0.0]\n",
      "[-] The AutoGen Framework -> 3  # 1 [108.0, 437.9809875488281, 0.0]\n",
      "    [*] Conversable Agents -> 3  # 1 [108.0, 337.41900634765625, 0.0]\n",
      "    [*] Conversation Programming -> 5  # 1 [108.0, 710.1380004882812, 0.0]\n",
      "[*] Applications of AutoGen -> 6  # 1 [108.0, 404.3290100097656, 0.0]\n",
      "[*] Discussion -> 10  # 1 [108.0, 641.5700073242188, 0.0]\n",
      "[*] Interfaces and Example Code -> 16  # 1 [108.0, 710.1380004882812, 0.0]\n",
      "[*] Expanded Related Work -> 17  # 1 [108.0, 710.1380004882812, 0.0]\n",
      "[-] Expanded Discussion -> 18  # 1 [108.0, 464.76300048828125, 0.0]\n",
      "    [*] General Guidelines for Using AutoGen -> 19  # 1 [108.0, 710.1380004882812, 0.0]\n",
      "    [*] Future Work -> 19  # 1 [108.0, 168.8459930419922, 0.0]\n",
      "[*] Default System Message for Assistant Agent -> 20  # 1 [108.0, 368.6730041503906, 0.0]\n",
      "[*] Application Details -> 20  # 1 [108.0, 218.94700622558594, 0.0]\n",
      "[*] Example outputs from applications -> 37  # 1 [108.0, 535.8150024414062, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for item in pdf.get_toc():\n",
    "    state = \"*\" if item.n_kids == 0 else \"-\" if item.is_closed else \"+\"\n",
    "    target = \"?\" if item.page_index is None else item.page_index+1\n",
    "    print(\n",
    "        \"    \" * item.level +\n",
    "        \"[%s] %s -> %s  # %s %s\" % (\n",
    "            state, item.title, target, item.view_mode, item.view_pos,\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ford_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
